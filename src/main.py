#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Personal AI Assistant - ä¸»å…¥å£

æ›¿ä»£ OpenClaw çš„ä¸ªäººæ™ºèƒ½åŠ©ç† - å®Œæ•´çš„é›†æˆç‰ˆæœ¬
"""
import argparse
import asyncio
import logging
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼Œä½¿ src ä½œä¸ºåŒ…å¯ç”¨
sys.path.insert(0, str(Path(__file__).parent.parent))

# åŠ è½½ .env æ–‡ä»¶
from dotenv import load_dotenv
load_dotenv(Path(__file__).parent.parent / '.env')

# è®¾ç½® logger
logger = logging.getLogger('pai')

from src.config.settings import Settings
from src.memory import MemorySystem, AutoConsolidationScheduler
from src.memory.embeddings import create_embedding_function, init_config
from src.chat.llm_client import create_llm_client
from src.chat.chat_session import ChatSession
from src.chat.simple_intent_handler import SimpleIntentHandler
from src.chat.action_router import ActionRouter
from src.task.manager import TaskManager
from src.schedule.scheduler import HybridScheduler
from src.search import SearchTool, WebSearchClient
from src.tools import (
    ToolExecutor, MCPClient, FunctionRegistry,
    MCPConfigManager, get_config_manager
)
from src.personality import get_personality_manager
from src.agent import create_agent_system, SupervisorAgent


def setup_logging(level: str = "INFO"):
    """è®¾ç½®æ—¥å¿—"""
    Path("data").mkdir(exist_ok=True)

    # æ ¹æ—¥å¿—çº§åˆ«
    log_level = getattr(logging, level.upper())

    # é…ç½®æ ¹æ—¥å¿—
    root_logger = logging.getLogger()
    root_logger.setLevel(log_level)

    # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
    root_logger.handlers.clear()

    # æ§åˆ¶å°å¤„ç†å™¨ - åªæ˜¾ç¤º WARNING åŠä»¥ä¸Šçº§åˆ«
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.WARNING)
    console_handler.setFormatter(logging.Formatter('%(levelname)s - %(message)s'))

    # æ–‡ä»¶å¤„ç†å™¨ - è®°å½•æ‰€æœ‰ INFO åŠä»¥ä¸Šçº§åˆ«
    file_handler = logging.FileHandler('data/app.log', encoding='utf-8')
    file_handler.setLevel(log_level)
    file_handler.setFormatter(logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    ))

    root_logger.addHandler(console_handler)
    root_logger.addHandler(file_handler)

    # é™ä½ç¬¬ä¸‰æ–¹åº“å’Œå†…éƒ¨è°ƒè¯•æ¨¡å—çš„æ—¥å¿—çº§åˆ«
    noisy_loggers = [
        'agent.tools.base',
        'chat.llm',
        'httpx',
        'httpcore',
        'urllib3',
        'asyncio',
        'memory.working',
        'memory.long_term',
        'memory.retrieval',
    ]
    for logger_name in noisy_loggers:
        logging.getLogger(logger_name).setLevel(logging.WARNING)


class PersonalAIAssistant:
    """ä¸ªäººAIåŠ©æ‰‹ä¸»ç±»"""

    def __init__(self, settings: Settings):
        self.settings = settings
        self.memory: MemorySystem | None = None
        self.chat_session: ChatSession | None = None
        self.task_manager: TaskManager | None = None
        self.scheduler: HybridScheduler | None = None
        self.llm = None
        self.search_tool = None
        self.tool_executor: ToolExecutor | None = None
        self.mcp_client: MCPClient | None = None
        self.mcp_config_manager: MCPConfigManager | None = None
        self.function_registry: FunctionRegistry | None = None
        self.personality_manager = None
        self.agent: SupervisorAgent | None = None  # æ–°å¢ Agent ç³»ç»Ÿ
        self.auto_consolidation: AutoConsolidationScheduler | None = None  # è‡ªåŠ¨è®°å¿†æ•´åˆ

    async def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        logger = logging.getLogger('pai')
        logger.info("æ­£åœ¨åˆå§‹åŒ–ä¸ªäººAIåŠ©æ‰‹...")

        # åˆ›å»ºæ•°æ®ç›®å½•
        Path(self.settings.data_dir).mkdir(parents=True, exist_ok=True)

        # è®¾ç½®åµŒå…¥é…ç½®ç¯å¢ƒå˜é‡
        import os
        if self.settings.embedding_base_url:
            os.environ['OLLAMA_BASE_URL'] = self.settings.embedding_base_url
        if self.settings.embedding_api_key:
            os.environ['OPENAI_API_KEY'] = self.settings.embedding_api_key

        # åˆå§‹åŒ–åµŒå…¥é…ç½®
        init_config()

        # åˆå§‹åŒ–æ€§æ ¼ç®¡ç†å™¨ï¼ˆçŒ«å¨˜ä¸ºé»˜è®¤æ€§æ ¼ï¼‰
        self.personality_manager = get_personality_manager()
        personality_name = os.environ.get('ASSISTANT_PERSONALITY', 'nekomata_assistant')
        if self.personality_manager.set_personality(personality_name):
            personality = self.personality_manager.get_current()
            logger.info(f"æ€§æ ¼å·²è®¾ç½®ä¸º: {personality.name} ({personality.self_reference})")
        else:
            logger.warning(f"æ€§æ ¼è®¾ç½®å¤±è´¥: {personality_name}")

        # åˆå§‹åŒ–åµŒå…¥å‡½æ•°
        embedding_func = create_embedding_function()

        # åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ
        self.memory = MemorySystem(
            data_dir=f"{self.settings.data_dir}/memories",
            embedding_func=embedding_func,
            llm_client=None
        )

        # åˆå§‹åŒ–å¹¶å¯åŠ¨è‡ªåŠ¨è®°å¿†æ•´åˆè°ƒåº¦å™¨ (OpenClaw é£æ ¼)
        self.auto_consolidation = AutoConsolidationScheduler(
            memory_system=self.memory,
            daily_hour=23,        # æ¯æ™š 11 ç‚¹
            weekly_day=6,         # å‘¨æ—¥
            weekly_hour=22,       # æ™šä¸Š 10 ç‚¹
            micro_sync_hours=[10, 13, 16, 19, 22]  # ç™½å¤©æ£€æŸ¥ç‚¹
        )
        await self.auto_consolidation.start()


        # åˆå§‹åŒ–ä»»åŠ¡ç®¡ç†å™¨
        self.task_manager = TaskManager(
            storage_path=f"{self.settings.data_dir}/tasks.jsonl"
        )

        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        if self.settings.llm_provider == 'openai':
            if not self.settings.llm_api_key:
                raise ValueError("ä½¿ç”¨ OpenAI éœ€è¦æä¾› API Key (é€šè¿‡ --llm-api-key æˆ– OPENAI_API_KEY ç¯å¢ƒå˜é‡)")
            self.llm = create_llm_client(
                provider='openai',
                api_key=self.settings.llm_api_key,
                base_url=self.settings.llm_base_url,
                model=self.settings.llm_model
            )
        elif self.settings.llm_provider == 'minimax':
            if not self.settings.llm_api_key:
                raise ValueError("ä½¿ç”¨ MiniMax éœ€è¦æä¾› API Key (é€šè¿‡ --llm-api-key æˆ– MINIMAX_API_KEY ç¯å¢ƒå˜é‡)")
            self.llm = create_llm_client(
                provider='minimax',
                api_key=self.settings.llm_api_key,
                base_url=self.settings.llm_base_url or 'https://api.minimaxi.com/v1',
                model=self.settings.llm_model or 'MiniMax-M2.5'
            )
            logger.info(f"å·²è¿æ¥ MiniMax API: {self.settings.llm_base_url}")
        else:
            # Ollama ä¸éœ€è¦ api_key
            self.llm = create_llm_client(
                provider='ollama',
                base_url=self.settings.llm_base_url,
                model=self.settings.llm_model
            )

        # æ›´æ–°è®°å¿†ç³»ç»Ÿçš„LLMå®¢æˆ·ç«¯
        self.memory.consolidation.llm_client = self.llm.generate

        # åˆå§‹åŒ–å¯¹è¯ä¼šè¯ï¼ˆä¼ å…¥æ€§æ ¼ç®¡ç†å™¨ï¼‰
        self.chat_session = ChatSession(
            session_id=self.settings.session_id,
            memory_system=self.memory,
            llm_client=self.llm,
            task_manager=self.task_manager,
            personality_manager=self.personality_manager
        )

        # åˆå§‹åŒ–è°ƒåº¦å™¨
        self.scheduler = HybridScheduler()

        # åˆå§‹åŒ–æœç´¢å·¥å…·
        try:
            web_search = WebSearchClient(
                default_engine=os.getenv('SEARCH_ENGINE', 'duckduckgo'),
                api_keys={
                    'bing': os.getenv('BING_API_KEY'),
                    'brave': os.getenv('BRAVE_API_KEY'),
                }
            )
            self.search_tool = SearchTool(
                web_search_client=web_search,
                llm_client=self.llm.generate,
                enable_auto_search=os.getenv('ENABLE_AUTO_SEARCH', 'false').lower() == 'true'
            )
            logger.info("æœç´¢åŠŸèƒ½å·²åˆå§‹åŒ–")
        except Exception as e:
            logger.warning(f"æœç´¢åŠŸèƒ½åˆå§‹åŒ–å¤±è´¥: {e}")
            self.search_tool = None

        # åˆå§‹åŒ– MCP å®¢æˆ·ç«¯å’Œå·¥å…·æ‰§è¡Œå™¨
        if self.settings.mcp_enabled:
            logger.info("æ­£åœ¨åˆå§‹åŒ– MCP å·¥å…·...")

            # ä½¿ç”¨é…ç½®ç®¡ç†å™¨è‡ªåŠ¨å‘ç°å’ŒåŠ è½½ MCP é…ç½®
            self.mcp_config_manager = get_config_manager(
                f"{self.settings.data_dir}/mcp_configs"
            )

            # ä»ç¯å¢ƒå˜é‡è‡ªåŠ¨å‘ç° MCP æœåŠ¡
            auto_count = self.mcp_config_manager.auto_discover_from_env()
            if auto_count > 0:
                logger.info(f"  âœ“ ä»ç¯å¢ƒå˜é‡å‘ç° {auto_count} ä¸ª MCP æœåŠ¡")

            # åˆ›å»º MCP å®¢æˆ·ç«¯å¹¶ä»é…ç½®ç®¡ç†å™¨åŠ è½½
            self.mcp_client = MCPClient(config_manager=self.mcp_config_manager)
            self.mcp_client.load_from_config_manager(self.mcp_config_manager)

            # æ‰‹åŠ¨é…ç½®ï¼ˆå¦‚æœç¯å¢ƒå˜é‡ä¸­æœ‰ä½†æœªè‡ªåŠ¨åŠ è½½ï¼‰
            if self.settings.mcp_amap_api_key and "amap" not in self.mcp_client.configs:
                self.mcp_client.add_preset("amap", self.settings.mcp_amap_api_key)
                logger.info("  âœ“ é«˜å¾·åœ°å›¾ MCP å·²é…ç½®")

            if self.settings.mcp_baidu_map_api_key and "baidu_map" not in self.mcp_client.configs:
                self.mcp_client.add_preset("baidu_map", self.settings.mcp_baidu_map_api_key)
                logger.info("  âœ“ ç™¾åº¦åœ°å›¾ MCP å·²é…ç½®")

            if self.settings.mcp_minimax_api_key and "minimax" not in self.mcp_client.configs:
                self.mcp_client.add_preset("minimax", self.settings.mcp_minimax_api_key)
                logger.info("  âœ“ MiniMax MCP å·²é…ç½®")

            if self.settings.mcp_glm_api_key and "glm" not in self.mcp_client.configs:
                self.mcp_client.add_preset("glm", self.settings.mcp_glm_api_key)
                logger.info("  âœ“ GLM MCP å·²é…ç½®")

            # æ³¨å†Œå†…ç½®å·¥å…·
            self.function_registry = FunctionRegistry()

            # åˆ›å»ºå·¥å…·æ‰§è¡Œå™¨
            self.tool_executor = ToolExecutor(
                mcp_client=self.mcp_client,
                function_registry=self.function_registry
            )

            # æ˜¾ç¤ºå¯ç”¨çš„å·¥å…·
            tools = self.tool_executor.get_available_tools()
            logger.info(f"MCP å·¥å…·åˆå§‹åŒ–å®Œæˆï¼Œå¯ç”¨å·¥å…·: {len(tools)} ä¸ª")

        # åˆå§‹åŒ–æç®€æ„å›¾å¤„ç†å™¨ï¼ˆLLM-First æ¶æ„ï¼‰
        logger.info("ä½¿ç”¨ LLM-First æ„å›¾å¤„ç†")
        self.intent_handler = SimpleIntentHandler(llm_client=self.llm.generate)

        # åˆå§‹åŒ–åŠ¨ä½œè·¯ç”±å™¨ï¼ˆæ—§ç³»ç»Ÿï¼Œä¿ç•™å…¼å®¹ï¼‰
        self.action_router = ActionRouter(
            memory_system=self.memory,
            task_manager=self.task_manager,
            llm_client=self.llm.generate,
            search_tool=self.search_tool,
            tool_executor=self.tool_executor
        )

        # åˆå§‹åŒ–æ–°çš„ Agent ç³»ç»Ÿï¼ˆSupervisor + Function Callingï¼‰
        logger.info("æ­£åœ¨åˆå§‹åŒ– Agent ç³»ç»Ÿ...")
        self.agent = create_agent_system(
            llm_client=self.llm,
            memory_system=self.memory,
            task_manager=self.task_manager,
            search_tool=self.search_tool,
            personality_manager=self.personality_manager,
            chat_session=self.chat_session,
            fast_path_classifier=None  # ä¸å†ä½¿ç”¨æ—§çš„æ„å›¾åˆ†ç±»å™¨
        )
        logger.info(f"Agent ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œå·²æ³¨å†Œ {len(self.agent.tools)} ä¸ªå·¥å…·")

        logger.info("åˆå§‹åŒ–å®Œæˆï¼")

    def _print_banner(self):
        """æ‰“å°å¯åŠ¨æ¨ªå¹…"""
        personality = self.personality_manager.get_current() if self.personality_manager else None
        persona_name = personality.self_reference if personality else "åŠ©æ‰‹"

        print("\n" + "=" * 50)
        print(f"ğŸ¤– Personal AI Assistant - {persona_name}")
        print("=" * 50)
        print("å‘½ä»¤:")
        print("  /quit, /q          - é€€å‡º")
        print("  /tasks, /t         - æŸ¥çœ‹ä»»åŠ¡åˆ—è¡¨")
        print("  /clear, /c         - æ¸…ç©ºå¯¹è¯å†å²")
        print("  /status, /s        - æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€")
        print("  /personality, /p   - æŸ¥çœ‹/åˆ‡æ¢æ€§æ ¼")
        print("  /consolidate       - æ‰‹åŠ¨æ•´åˆè®°å¿†")
        print("  /export            - å¯¼å‡ºè®°å¿†æ•°æ®")
        print("  /help, /h          - æ˜¾ç¤ºå¸®åŠ©")
        print("=" * 50 + "\n")

    async def interactive_chat(self):
        """äº¤äº’å¼å¯¹è¯æ¨¡å¼"""
        self._print_banner()

        while True:
            try:
                user_input = input("ğŸ‘¤ ä½ : ").strip()

                if not user_input:
                    continue

                # å¤„ç†å‘½ä»¤
                if user_input.startswith('/'):
                    if await self._handle_command(user_input):
                        break
                    continue

                # ä½¿ç”¨æ–°çš„ Agent ç³»ç»Ÿå¤„ç†
                print("ğŸ¤– åŠ©æ‰‹: ", end='', flush=True)
                try:
                    async for output in self.agent.handle(user_input, session_id=self.settings.session_id):
                        if isinstance(output, dict) and output.get("type") == "need_input":
                            # éœ€è¦ç”¨æˆ·ç¡®è®¤
                            print(f"\nğŸ’­ {output.get('prompt', 'è¯·ç¡®è®¤')}")
                            confirm = input("ä½ çš„å›å¤: ").strip()
                            # ç»§ç»­å¤„ç†ç¡®è®¤
                            print("ğŸ¤– åŠ©æ‰‹: ", end='', flush=True)
                            async for confirm_output in self.agent.continue_with_input(confirm, self.agent._current_context):
                                print(confirm_output, end='', flush=True)
                        else:
                            print(output, end='', flush=True)
                    print()  # æ¢è¡Œ
                    print()
                except Exception as e:
                    logger.error(f"Agent å¤„ç†é”™è¯¯: {e}")
                    print(f"\nâŒ é”™è¯¯: {e}")
                    continue

            except KeyboardInterrupt:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                logging.error(f"å¯¹è¯é”™è¯¯: {e}")
                print(f"âŒ é”™è¯¯: {e}")

    async def _handle_command(self, cmd: str) -> bool:
        """å¤„ç†å‘½ä»¤ï¼Œè¿”å›Trueè¡¨ç¤ºé€€å‡º"""
        cmd = cmd.lower()

        if cmd in ['/quit', '/q', 'exit']:
            print("ğŸ‘‹ å†è§ï¼")
            return True

        elif cmd in ['/tasks', '/t']:
            self._show_tasks()

        elif cmd in ['/clear', '/c']:
            self.chat_session.clear_history()
            print("ğŸ—‘ï¸ å¯¹è¯å†å²å·²æ¸…ç©º")

        elif cmd in ['/status', '/s']:
            self._show_status()

        elif cmd in ['/consolidate', '/merge']:
            print("ğŸ”„ æ­£åœ¨æ•´åˆè®°å¿†...")
            stats = self.memory.consolidate()
            print("âœ… æ•´åˆå®Œæˆ:")
            print(f"  æ”¶é›†: {stats.get('collected', 0)}")
            print(f"  æå–äº‹å®: {stats.get('facts_extracted', 0)}")

        elif cmd == '/stats':
            stats = self.memory.get_stats()
            print("\nğŸ“Š è®°å¿†ç»Ÿè®¡:")
            print(f"  è®°å¿†æ€»æ•°: {stats.get('total', 0)}")
            print(f"  æ–°å¢è®°å¿†: {stats.get('memories_added', 0)}")
            print(f"  æ£€ç´¢æ¬¡æ•°: {stats.get('memories_retrieved', 0)}")

        elif cmd in ['/export', '/e']:
            print("ğŸ“¤ æ­£åœ¨å¯¼å‡ºæ•°æ®...")
            result = self.action_router._handle_export_data(
                type('Intent', (), {'raw_text': ''})(), ''
            )
            if result.success:
                print(f"âœ… {result.message}")
            else:
                print(f"âŒ å¯¼å‡ºå¤±è´¥: {result.message}")

        elif cmd in ['/personality', '/p']:
            """åˆ‡æ¢æ€§æ ¼"""
            personalities = self.personality_manager.list_personalities()
            current = self.personality_manager.get_current()

            print(f"\nğŸ­ å½“å‰æ€§æ ¼: {current.name} ({current.self_reference})")
            print("\nå¯ç”¨æ€§æ ¼:")
            for i, p in enumerate(personalities, 1):
                marker = " âœ“" if p['name'] == current.name else ""
                print(f"  {i}. {p['name']}: {p['description']}{marker}")
            print("\nåˆ‡æ¢æ€§æ ¼: /personality <æ€§æ ¼å>")
            print("  ä¾‹å¦‚: /personality ojousama_assistant")

        elif cmd.startswith('/personality '):
            """è®¾ç½®æ€§æ ¼"""
            personality_name = cmd[13:].strip()
            if self.personality_manager.set_personality(personality_name):
                new_personality = self.personality_manager.get_current()
                # é‡æ–°åˆå§‹åŒ– ChatSession ä»¥åº”ç”¨æ–°çš„æ€§æ ¼
                self.chat_session = ChatSession(
                    session_id=self.settings.session_id,
                    memory_system=self.memory,
                    llm_client=self.llm,
                    task_manager=self.task_manager,
                    personality_manager=self.personality_manager
                )
                print(f"âœ… æ€§æ ¼å·²åˆ‡æ¢ä¸º: {new_personality.name}")
                print(f"   è‡ªç§°: {new_personality.self_reference}")
                print(f"   å¯¹æ‚¨çš„ç§°å‘¼: {new_personality.user_reference}")
            else:
                print(f"âŒ æ— æ•ˆçš„æ€§æ ¼: {personality_name}")
                print("å¯ç”¨: nekomata_assistant, ojousama_assistant, default_assistant")

        elif cmd in ['/help', '/h']:
            personality = self.personality_manager.get_current()
            print(f"""
ğŸ¤– Personal AI Assistant å¸®åŠ©

å½“å‰æ€§æ ¼: {personality.name} ({personality.self_reference})

ğŸ“‹ ä»»åŠ¡ç®¡ç†:
  â€¢ åˆ›å»ºä»»åŠ¡: "æ˜å¤©ä¸‹åˆ3ç‚¹å¼€ä¼š"
  â€¢ æŸ¥çœ‹ä»»åŠ¡: /tasks, /t
  â€¢ è®¾ç½®æé†’: "10åˆ†é’Ÿåæé†’æˆ‘å–æ°´"

ğŸ§  è®°å¿†ç®¡ç†:
  â€¢ è®°å½•ä¿¡æ¯: "è®°ä½æˆ‘å–œæ¬¢Python"
  â€¢ æŸ¥è¯¢è®°å¿†: "æˆ‘ä¹‹å‰è¯´è¿‡ä»€ä¹ˆ"
  â€¢ æ•´åˆè®°å¿†: /consolidate

ğŸ­ æ€§æ ¼è®¾ç½®:
  â€¢ æŸ¥çœ‹æ€§æ ¼: /personality, /p
  â€¢ åˆ‡æ¢æ€§æ ¼: /personality <æ€§æ ¼å>

âš™ï¸  ç³»ç»Ÿå‘½ä»¤:
  â€¢ é€€å‡º: /quit, /q
  â€¢ æ¸…ç©ºå¯¹è¯: /clear, /c
  â€¢ æŸ¥çœ‹çŠ¶æ€: /status, /s
  â€¢ å¯¼å‡ºæ•°æ®: /export, /e
  â€¢ å¸®åŠ©: /help, /h
            """)

        else:
            print(f"â“ æœªçŸ¥å‘½ä»¤: {cmd}")

        return False

    def _show_tasks(self):
        """æ˜¾ç¤ºä»»åŠ¡åˆ—è¡¨"""

        tasks = self.task_manager.list_tasks(status="pending")
        if not tasks:
            print("ğŸ“‹ æš‚æ— å¾…åŠä»»åŠ¡")
            return

        print(f"\nğŸ“‹ å¾…åŠä»»åŠ¡ ({len(tasks)}ä¸ª):")
        print("-" * 70)

        for task in tasks[:10]:
            # æ ¹æ®ä¼˜å…ˆçº§åˆ†æ•°é€‰æ‹© emoji
            priority_score = task.priority.calculate()
            if priority_score >= 0.7:
                priority_emoji = "ğŸ”´"
            elif priority_score >= 0.4:
                priority_emoji = "ğŸŸ¡"
            else:
                priority_emoji = "ğŸŸ¢"

            # ä»»åŠ¡ç±»å‹æ ‡ç­¾
            type_emoji = {
                "immediate": "âš¡",
                "todo": "ğŸ“",
                "scheduled": "ğŸ“…",
                "recurring": "ğŸ”„",
                "triggered": "ğŸ”—",
                "delegated": "ğŸ‘¤",
            }.get(task.task_type.value, "ğŸ“Œ")

            # ç¬¬ä¸€è¡Œï¼šæ ‡é¢˜ + æ‰§è¡Œ/æˆªæ­¢æ—¶é—´
            exec_time = ""
            if task.scheduled_at:
                exec_time = f"â° æ‰§è¡Œ: {task.scheduled_at.strftime('%m-%d %H:%M')}"
            elif task.due_date:
                exec_time = f"ğŸ“… æˆªæ­¢: {task.due_date.strftime('%m-%d %H:%M')}"

            if exec_time:
                print(f"{priority_emoji} [{task.id[:8]}] {type_emoji} {task.title}")
                print(f"      {exec_time}")
            else:
                print(f"{priority_emoji} [{task.id[:8]}] {type_emoji} {task.title}")

            # ç¬¬äºŒè¡Œï¼šæè¿°ï¼ˆå¦‚æœæœ‰ï¼‰
            if task.description:
                desc = task.description[:45] + "..." if len(task.description) > 45 else task.description
                print(f"      ğŸ“ {desc}")

            # ç¬¬ä¸‰è¡Œï¼šæ·»åŠ æ—¶é—´ + æ ‡ç­¾
            meta_info = []
            if task.created_at:
                meta_info.append(f"ğŸ“Œ æ·»åŠ : {task.created_at.strftime('%m-%d %H:%M')}")
            if task.tags:
                meta_info.append(f"ğŸ·ï¸ {','.join(task.tags[:3])}")
            if task.waiting_for:
                meta_info.append(f"â³ ç­‰å¾…: {task.waiting_for}")

            if meta_info:
                print(f"      {' | '.join(meta_info)}")

            print()

        if len(tasks) > 10:
            print(f"... è¿˜æœ‰ {len(tasks) - 10} ä¸ªä»»åŠ¡")
        print("-" * 70)

    def _show_status(self):
        """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€"""
        summary = self.chat_session.get_summary()
        print("\nğŸ“Š ç³»ç»ŸçŠ¶æ€:")
        print("-" * 40)
        print(f"ä¼šè¯ID: {summary['session_id']}")
        print(f"è¿è¡Œæ—¶é•¿: {summary['duration_seconds']:.0f}ç§’")
        print(f"å¯¹è¯è½®æ•°: {summary['user_message_count']}")

        wm = self.memory.working_memory
        print(f"\nå·¥ä½œè®°å¿†æ§½ä½: {len(wm.slots)}/10")
        for key in wm.slots:
            print(f"  â€¢ {key}")

        all_tasks = self.task_manager.list_tasks()
        pending = len([t for t in all_tasks if t.status.value == "pending"])
        completed = len([t for t in all_tasks if t.status.value == "completed"])
        print(f"\nä»»åŠ¡ç»Ÿè®¡: å¾…åŠ {pending} | å®Œæˆ {completed}")
        print()

    async def run_single(self, command: str):
        """æ‰§è¡Œå•æ¬¡ä»»åŠ¡"""
        response = self.chat_session.chat(command)
        print(response)

    async def shutdown(self):
        """å…³é—­æ‰€æœ‰ç»„ä»¶"""
        logger = logging.getLogger('pai')
        logger.info("æ­£åœ¨å…³é—­...")
        if self.auto_consolidation:
            await self.auto_consolidation.stop()
        if self.scheduler:
            await self.scheduler.stop_all()
        if self.memory:
            self.memory.close()
        logger.info("å·²å…³é—­")


async def async_main():
    """å¼‚æ­¥ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Personal AI Assistant')
    parser.add_argument('-c', '--command', help='æ‰§è¡Œå•æ¬¡å‘½ä»¤åé€€å‡º')
    parser.add_argument('--data-dir', default=os.getenv('DATA_DIR', './data'), help='æ•°æ®ç›®å½•')
    parser.add_argument('--log-level', default=os.getenv('LOG_LEVEL', 'INFO'), help='æ—¥å¿—çº§åˆ«')
    parser.add_argument('--llm-provider', default=os.getenv('LLM_PROVIDER', 'ollama'), choices=['openai', 'ollama', 'minimax'])
    parser.add_argument('--llm-model', default=os.getenv('LLM_MODEL', 'qwen2.5:14b'), help='LLMæ¨¡å‹')
    parser.add_argument('--llm-api-key', default=os.getenv('LLM_API_KEY'), help='OpenAI API Key (ä»…OpenAIéœ€è¦)')
    parser.add_argument('--llm-base-url', default=os.getenv('LLM_BASE_URL'), help='LLMåŸºç¡€URL')
    parser.add_argument('--embedding-provider', default=os.getenv('EMBEDDING_PROVIDER', 'ollama'), choices=['openai', 'ollama'])
    args = parser.parse_args()

    setup_logging(args.log_level)

    # åŠ è½½é…ç½®ï¼ˆä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œå‚æ•° > ç¯å¢ƒå˜é‡ > é»˜è®¤å€¼ï¼‰
    # æ³¨æ„ï¼šargparse é»˜è®¤å€¼å·²ä»ç¯å¢ƒå˜é‡è¯»å–
    settings = Settings(
        data_dir=args.data_dir,
        llm_provider=args.llm_provider,
        llm_model=args.llm_model,
        llm_api_key=args.llm_api_key,
        llm_base_url=args.llm_base_url,
        embedding_provider=args.embedding_provider,
        embedding_model=os.getenv('EMBEDDING_MODEL', 'nomic-embed-text'),
        embedding_base_url=os.getenv('EMBEDDING_BASE_URL', 'http://localhost:11434'),
    )

    assistant = PersonalAIAssistant(settings)

    try:
        await assistant.initialize()

        if args.command:
            await assistant.run_single(args.command)
        else:
            await assistant.interactive_chat()

    finally:
        await assistant.shutdown()


def main():
    """ä¸»å…¥å£"""
    asyncio.run(async_main())


if __name__ == "__main__":
    main()
