# -*- coding: utf-8 -*-
"""
Supervisor Agent

åŸºäº Supervisor æ¨¡å¼çš„æ™ºèƒ½ä½“å®ç°
æ”¯æŒä¸‰å±‚æ‰§è¡Œæ¨¡å¼ï¼šFast Path / Single Step / Multi Step
"""
import asyncio
import inspect
import json
import logging
import time
from dataclasses import dataclass, field
from enum import Enum
from functools import wraps
from typing import AsyncGenerator, Optional, TYPE_CHECKING

from .tools.base import ToolResult
from .tools.registry import ToolRegistry
from .llm_adapter import create_llm_adapter, LLMAdapter

if TYPE_CHECKING:
    from memory import MemorySystem

logger = logging.getLogger('agent.supervisor')


class MetricsCollector:
    """æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self):
        self.metrics = {
            'llm_calls': 0,
            'llm_latency': [],
            'tool_calls': {},
            'tool_latency': {},
            'mode_usage': {
                'fast_path': 0,
                'single_step': 0,
                'multi_step': 0
            },
            'errors': []
        }

    def record_llm_call(self, duration: float):
        """è®°å½• LLM è°ƒç”¨"""
        self.metrics['llm_calls'] += 1
        self.metrics['llm_latency'].append(duration)

    def record_tool_call(self, tool_name: str, duration: float, success: bool):
        """è®°å½•å·¥å…·è°ƒç”¨"""
        if tool_name not in self.metrics['tool_calls']:
            self.metrics['tool_calls'][tool_name] = {'success': 0, 'failed': 0}
            self.metrics['tool_latency'][tool_name] = []

        self.metrics['tool_calls'][tool_name]['success' if success else 'failed'] += 1
        self.metrics['tool_latency'][tool_name].append(duration)

    def record_mode(self, mode: str):
        """è®°å½•æ‰§è¡Œæ¨¡å¼ä½¿ç”¨"""
        self.metrics['mode_usage'][mode] = self.metrics['mode_usage'].get(mode, 0) + 1

    def record_error(self, error: str):
        """è®°å½•é”™è¯¯"""
        self.metrics['errors'].append({'time': time.time(), 'error': error})

    def get_summary(self) -> dict:
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        summary = {
            'llm_calls': self.metrics['llm_calls'],
            'llm_avg_latency': sum(self.metrics['llm_latency']) / len(self.metrics['llm_latency']) if self.metrics['llm_latency'] else 0,
            'tool_usage': self.metrics['tool_calls'],
            'mode_distribution': self.metrics['mode_usage'],
            'error_count': len(self.metrics['errors'])
        }

        # è®¡ç®—å„å·¥å…·å¹³å‡å»¶è¿Ÿ
        tool_avg_latency = {}
        for tool_name, latencies in self.metrics['tool_latency'].items():
            if latencies:
                tool_avg_latency[tool_name] = sum(latencies) / len(latencies)
        summary['tool_avg_latency'] = tool_avg_latency

        return summary


def timed(metric_name: str = None):
    """æ€§èƒ½è®¡æ—¶è£…é¥°å™¨ï¼ˆæ”¯æŒå¼‚æ­¥å‡½æ•°å’Œå¼‚æ­¥ç”Ÿæˆå™¨ï¼‰"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start = time.time()
            name = metric_name or func.__name__

            # ä½¿ç”¨ inspect æ›´å¯é åœ°æ£€æµ‹å¼‚æ­¥ç”Ÿæˆå™¨
            if inspect.isasyncgenfunction(func):
                # å¼‚æ­¥ç”Ÿæˆå™¨
                async def async_gen_wrapper():
                    try:
                        async for item in func(*args, **kwargs):
                            yield item
                    finally:
                        duration = time.time() - start
                        logger.debug(f"[æ€§èƒ½] {name}: {duration:.3f}s")
                return async_gen_wrapper()
            else:
                # æ™®é€šå¼‚æ­¥å‡½æ•°
                async def async_wrapper():
                    try:
                        return await func(*args, **kwargs)
                    finally:
                        duration = time.time() - start
                        logger.debug(f"[æ€§èƒ½] {name}: {duration:.3f}s")
                return async_wrapper()
        return wrapper
    return decorator


class ExecutionMode(Enum):
    """æ‰§è¡Œæ¨¡å¼"""
    FAST_PATH = "fast_path"      # Tier 2: å¿«é€Ÿè·¯å¾„ï¼ˆSemantic Routerï¼‰
    SINGLE_STEP = "single_step"  # Tier 3: å•æ­¥ Function Calling
    MULTI_STEP = "multi_step"    # Tier 4: å¤šæ­¥ Agent æ¨¡å¼


@dataclass
class Step:
    """æ‰§è¡Œæ­¥éª¤"""
    id: str
    tool_name: str
    parameters: dict
    status: str = "pending"  # pending, running, completed, failed
    result: Optional[ToolResult] = None
    observation: str = ""


@dataclass
class ExecutionPlan:
    """æ‰§è¡Œè®¡åˆ’"""
    mode: ExecutionMode
    goal: str
    steps: list[Step] = field(default_factory=list)
    current_step: int = 0

    @property
    def is_complete(self) -> bool:
        return self.current_step >= len(self.steps)

    @property
    def current(self) -> Optional[Step]:
        if 0 <= self.current_step < len(self.steps):
            return self.steps[self.current_step]
        return None

    def next(self) -> Optional[Step]:
        """ç§»åŠ¨åˆ°ä¸‹ä¸€æ­¥"""
        self.current_step += 1
        return self.current


@dataclass
class AgentContext:
    """Agent ä¸Šä¸‹æ–‡"""
    session_id: str
    user_input: str
    plan: Optional[ExecutionPlan] = None
    history: list[dict] = field(default_factory=list)
    metadata: dict = field(default_factory=dict)


class SupervisorAgent:
    """
    Supervisor Agent

    èŒè´£ï¼š
    1. æ„å›¾åˆ†æ â†’ é€‰æ‹©æ‰§è¡Œæ¨¡å¼
    2. ä»»åŠ¡è§„åˆ’ â†’ ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
    3. ç¼–æ’æ‰§è¡Œ â†’ åè°ƒå·¥å…·æ‰§è¡Œ
    4. ç»“æœèšåˆ â†’ ç”Ÿæˆæœ€ç»ˆå›å¤
    """

    def __init__(
        self,
        llm_client,
        tool_registry: ToolRegistry,
        fast_path_classifier=None,
        memory_system: Optional['MemorySystem'] = None,
        max_steps: int = 10,
        retry_attempts: int = 3,
        retry_delay: float = 1.0,
        enable_memory_context: bool = True,
        context_memory_limit: int = 5
    ):
        self.llm: LLMAdapter = create_llm_adapter(llm_client)
        self.tools = tool_registry
        self.fast_path = fast_path_classifier
        self.memory = memory_system
        self.max_steps = max_steps
        self.retry_attempts = retry_attempts
        self.retry_delay = retry_delay
        self.enable_memory_context = enable_memory_context
        self.context_memory_limit = context_memory_limit
        self.schemas = tool_registry.get_schemas()
        self._current_context: Optional[AgentContext] = None
        self.metrics = MetricsCollector()
        self.enable_streaming = True  # é»˜è®¤å¯ç”¨æµå¼è¾“å‡º

        # ç¡®è®¤çŠ¶æ€è·Ÿè¸ª
        self._pending_confirmation: Optional[dict] = None  # ç­‰å¾…ç¡®è®¤çš„å·¥å…·è°ƒç”¨

    def _is_confirmation(self, user_input: str) -> bool:
        """æ£€æŸ¥ç”¨æˆ·è¾“å…¥æ˜¯å¦æ˜¯ç¡®è®¤"""
        confirmation_keywords = ['ç¡®è®¤', 'yes', 'æ˜¯', 'ç¡®å®š', 'å¥½çš„', 'æ‰§è¡Œ', 'åˆ é™¤', 'æ¸…ç†']
        return user_input.lower().strip() in confirmation_keywords

    def _is_cancel(self, user_input: str) -> bool:
        """æ£€æŸ¥ç”¨æˆ·è¾“å…¥æ˜¯å¦æ˜¯å–æ¶ˆ"""
        cancel_keywords = ['å–æ¶ˆ', 'cancel', 'no', 'å¦', 'ä¸', 'ç®—äº†', 'ä¸è¦']
        return user_input.lower().strip() in cancel_keywords

    async def _execute_confirmation(self, user_input: str) -> AsyncGenerator[str, None]:
        """æ‰§è¡Œç¡®è®¤çš„æ“ä½œ"""
        if not self._pending_confirmation:
            yield "æ²¡æœ‰å¾…ç¡®è®¤çš„æ“ä½œ\n"
            return

        pending = self._pending_confirmation

        # æ£€æŸ¥æ˜¯å¦æ˜¯å–æ¶ˆ
        if self._is_cancel(user_input):
            self._pending_confirmation = None
            yield "å·²å–æ¶ˆæ“ä½œ\n"
            return

        # æ‰§è¡Œç¡®è®¤
        tool_name = pending['tool_name']
        params = pending['params'].copy()
        params['confirmed'] = True

        # å¯¹äºåˆ é™¤æ“ä½œï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®š task_idsï¼Œé»˜è®¤åˆ é™¤æ‰€æœ‰
        if tool_name == "delete_tasks":
            if not params.get('task_ids') and not params.get('delete_all'):
                params['delete_all'] = True

        yield "ğŸ¤” "
        result = await self.tools.execute(tool_name, timeout=30.0, **params)

        # æ¸…é™¤ç¡®è®¤çŠ¶æ€
        self._pending_confirmation = None

        if result.success:
            yield result.observation + "\n"
        else:
            yield f"æ“ä½œå¤±è´¥: {result.observation}\n"

    async def _generate_response_stream(
        self,
        messages: list[dict],
        temperature: float = 0.7,
        max_tokens: int = 1000
    ) -> AsyncGenerator[str, None]:
        """
        æµå¼ç”Ÿæˆå›å¤

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            temperature: æ¸©åº¦
            max_tokens: æœ€å¤§tokenæ•°

        Yields:
            æ–‡æœ¬ç‰‡æ®µ
        """
        try:
            async for chunk in self.llm.stream_generate(messages, temperature, max_tokens):
                yield chunk
        except Exception as e:
            logger.warning(f"æµå¼ç”Ÿæˆå¤±è´¥: {e}")
            # é™çº§åˆ°æ‰¹é‡ç”Ÿæˆ
            response = await self.llm.generate(messages, temperature, max_tokens)
            yield response

    async def handle(
        self,
        user_input: str,
        session_id: str,
        context: Optional[dict] = None
    ) -> AsyncGenerator[str | dict, None]:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            session_id: ä¼šè¯ID
            context: é¢å¤–ä¸Šä¸‹æ–‡

        Yields:
            str: æµå¼è¾“å‡ºæ–‡æœ¬
            dict: éœ€è¦ç”¨æˆ·è¾“å…¥ {"type": "need_input", "prompt": str}
        """
        # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„ç¡®è®¤
        if self._pending_confirmation and self._is_confirmation(user_input):
            # æ‰§è¡Œç¡®è®¤çš„æ“ä½œ
            async for output in self._execute_confirmation(user_input):
                yield output
            return

        agent_context = AgentContext(
            session_id=session_id,
            user_input=user_input,
            metadata=context or {}
        )
        self._current_context = agent_context

        # Step 1: æ„å›¾åˆ†æ
        mode = await self._analyze_intent(user_input)
        logger.debug(f"æ‰§è¡Œæ¨¡å¼: {mode.value}")

        # Step 2: è§„åˆ’
        yield "ğŸ¤” "
        agent_context.plan = await self._plan(user_input, mode)

        if mode == ExecutionMode.MULTI_STEP:
            yield f"è®¡åˆ’ {len(agent_context.plan.steps)} æ­¥\n"

        # Step 3: æ‰§è¡Œ
        if mode == ExecutionMode.FAST_PATH and self.fast_path:
            async for output in self._execute_fast_path(agent_context):
                yield output
        elif mode == ExecutionMode.SINGLE_STEP:
            async for output in self._execute_single_step(agent_context):
                yield output
        elif mode == ExecutionMode.MULTI_STEP:
            async for output in self._execute_multi_step(agent_context):
                yield output

    def _build_context_messages(self, user_input: str) -> list[dict]:
        """
        æ„å»ºå¸¦è®°å¿†ä¸Šä¸‹æ–‡çš„ messages

        å¦‚æœå¯ç”¨äº† memory_contextï¼Œä¼šæœç´¢ç›¸å…³è®°å¿†å¹¶æ³¨å…¥ç³»ç»Ÿæç¤º
        """
        from datetime import datetime
        messages = []

        # åŸºç¡€ç³»ç»Ÿæç¤ºè¯ï¼ˆå‚è€ƒ OpenClaw æ¶æ„ï¼‰
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        base_system = f"""ä½ æ˜¯ç”¨æˆ·çš„ä¸ªäºº AI åŠ©æ‰‹ï¼Œæ€§æ ¼å‹å¥½ã€é«˜æ•ˆã€å¯é ã€‚

ã€å½“å‰æ—¶é—´ã€‘{current_time}

ã€æ ¸å¿ƒèŒè´£ã€‘
1. å‡†ç¡®ç†è§£ç”¨æˆ·æ„å›¾ï¼Œé€‰æ‹©æ­£ç¡®çš„å·¥å…·æ‰§è¡Œä»»åŠ¡
2. å½“ç”¨æˆ·è¯´"æ¸…ç†"ã€"åˆ é™¤"ã€"ç§»é™¤"æ—¶ï¼Œåº”è¯¥æ‰§è¡Œåˆ é™¤æ“ä½œï¼Œè€Œä¸æ˜¯åªæŸ¥çœ‹
3. å½“ç”¨æˆ·è¯´"æŸ¥çœ‹"ã€"æ˜¾ç¤º"ã€"æœ‰ä»€ä¹ˆ"æ—¶ï¼Œæ‰æ‰§è¡ŒæŸ¥çœ‹æ“ä½œ

ã€å·¥å…·é€‰æ‹©æŒ‡å—ã€‘
- ç”¨æˆ·è¯´"æ¸…ç†ä»»åŠ¡/åˆ é™¤ä»»åŠ¡" â†’ delete_tasksï¼ˆæ‰§è¡Œåˆ é™¤ï¼‰
- ç”¨æˆ·è¯´"æŸ¥çœ‹ä»»åŠ¡/æœ‰ä»€ä¹ˆä»»åŠ¡" â†’ list_tasksï¼ˆä»…æŸ¥çœ‹ï¼‰
- ç”¨æˆ·è¯´"å®Œæˆä»»åŠ¡" â†’ complete_task
- ç”¨æˆ·è¯´"åˆ›å»ºä»»åŠ¡/æé†’æˆ‘" â†’ create_task"""

        # å¦‚æœå¯ç”¨è®°å¿†ä¸Šä¸‹æ–‡ä¸”æœ‰è®°å¿†ç³»ç»Ÿ
        memory_context = ""
        if self.enable_memory_context and self.memory:
            try:
                # ä½¿ç”¨ recall æ–¹æ³•æ£€ç´¢ç›¸å…³è®°å¿†
                raw_memory = self.memory.recall(
                    query=user_input,
                    top_k=min(self.context_memory_limit, 3)  # é™åˆ¶è®°å¿†æ•°é‡
                )
                # é™åˆ¶è®°å¿†å†…å®¹é•¿åº¦ï¼ˆæœ€å¤š 1500 å­—ç¬¦ï¼‰
                if raw_memory and raw_memory.strip():
                    memory_context = raw_memory[:1500]
                    if len(raw_memory) > 1500:
                        memory_context += "\n...ï¼ˆè®°å¿†å†…å®¹å·²æˆªæ–­ï¼‰"
                    logger.debug(f"å·²æ³¨å…¥ç›¸å…³è®°å¿†ä¸Šä¸‹æ–‡ ({len(memory_context)} å­—ç¬¦)")
            except Exception as e:
                logger.warning(f"æ£€ç´¢è®°å¿†å¤±è´¥: {e}")

        # ç»„åˆç³»ç»Ÿæç¤ºè¯
        if memory_context:
            system_prompt = f"""{base_system}

ã€ç›¸å…³è®°å¿†ã€‘
{memory_context}"""
        else:
            system_prompt = base_system

        messages.append({"role": "system", "content": system_prompt})

        # æ·»åŠ ç”¨æˆ·è¾“å…¥
        messages.append({"role": "user", "content": user_input})
        return messages

    @timed("analyze_intent")
    async def _analyze_intent(self, user_input: str) -> ExecutionMode:
        """
        åˆ†ææ„å›¾ï¼Œå†³å®šæ‰§è¡Œæ¨¡å¼

        å¯å‘å¼åˆ¤æ–­ï¼Œé¿å…ä¸å¿…è¦çš„ LLM è°ƒç”¨
        """
        user_input_lower = user_input.lower()

        # ç®€å•é—®å€™ â†’ Fast Path
        simple_patterns = ["ä½ å¥½", "å—¨", "hello", "hi", "è°¢è°¢", "å†è§", "æ‹œæ‹œ"]
        if any(p in user_input_lower for p in simple_patterns):
            if len(user_input) < 20:  # çŸ­æ¶ˆæ¯æ‰èµ° fast path
                return ExecutionMode.FAST_PATH

        # å¤æ‚å¤šæ­¥æŒ‡ç¤º â†’ Multi Stepï¼ˆéœ€è¦è§„åˆ’å’Œå¤šå·¥å…·åä½œï¼‰
        complex_multi_indicators = [
            "ç„¶å", "å…ˆ...å†", "å¸®æˆ‘...ç„¶å", "æ•´ç†å¹¶", "æ€»ç»“æ‰€æœ‰", "åˆ†æå¹¶"
        ]
        if any(i in user_input for i in complex_multi_indicators):
            return ExecutionMode.MULTI_STEP

        # ä»»åŠ¡æ¸…ç†/åˆ é™¤ â†’ Single Stepï¼ˆç›´æ¥ Function Callingï¼Œå·¥å…·ä¼šå¤„ç†ç¡®è®¤æµç¨‹ï¼‰
        # æ³¨æ„ï¼šä¸å†èµ° Multi Stepï¼Œè®© LLM ç›´æ¥é€‰æ‹© delete_tasks å·¥å…·
        delete_keywords = ["æ¸…ç†ä»»åŠ¡", "åˆ é™¤ä»»åŠ¡", "æ¸…ç©ºä»»åŠ¡", "ç§»é™¤ä»»åŠ¡", "åˆ é™¤è¿™äº›", "æ¸…ç†è¿™äº›"]
        if any(kw in user_input for kw in delete_keywords):
            return ExecutionMode.SINGLE_STEP

        # æŸ¥çœ‹/æŸ¥è¯¢ â†’ Single Step
        view_keywords = ["æœ‰ä»€ä¹ˆä»»åŠ¡", "æŸ¥çœ‹ä»»åŠ¡", "å¾…åŠ", "æ˜¾ç¤ºä»»åŠ¡", "åˆ—å‡º"]
        if any(kw in user_input for kw in view_keywords):
            return ExecutionMode.SINGLE_STEP

        # é»˜è®¤ â†’ Single Step (Function Calling)
        return ExecutionMode.SINGLE_STEP

    async def _plan(self, user_input: str, mode: ExecutionMode) -> ExecutionPlan:
        """ç”Ÿæˆæ‰§è¡Œè®¡åˆ’"""

        if mode == ExecutionMode.FAST_PATH:
            # Fast path ä¸éœ€è¦è¯¦ç»†è§„åˆ’
            return ExecutionPlan(
                mode=mode,
                goal=user_input,
                steps=[]
            )

        elif mode == ExecutionMode.SINGLE_STEP:
            # ä½¿ç”¨ Function Calling é€‰æ‹©å·¥å…·ï¼ˆå¸¦é‡è¯•ï¼‰
            return await self._plan_single_step_with_retry(user_input)

        elif mode == ExecutionMode.MULTI_STEP:
            # ä½¿ç”¨ LLM è¿›è¡Œå¤šæ­¥è§„åˆ’ï¼ˆå¸¦é‡è¯•ï¼‰
            return await self._plan_multi_step_with_retry(user_input)

        return ExecutionPlan(mode=mode, goal=user_input, steps=[])

    async def _plan_single_step_with_retry(self, user_input: str) -> ExecutionPlan:
        """å•æ­¥è§„åˆ’ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        for attempt in range(self.retry_attempts):
            try:
                return await self._plan_single_step(user_input)
            except Exception as e:
                logger.warning(f"å•æ­¥è§„åˆ’å°è¯• {attempt + 1} å¤±è´¥: {e}")
                if attempt < self.retry_attempts - 1:
                    await asyncio.sleep(self.retry_delay * (attempt + 1))
                else:
                    logger.error(f"å•æ­¥è§„åˆ’æœ€ç»ˆå¤±è´¥: {e}")

        # Fallback: ç›´æ¥å¯¹è¯
        return ExecutionPlan(
            mode=ExecutionMode.SINGLE_STEP,
            goal=user_input,
            steps=[Step(
                id="step_0",
                tool_name="chat",
                parameters={"message": user_input}
            )]
        )

    @timed("plan_single_step")
    async def _plan_single_step(self, user_input: str) -> ExecutionPlan:
        """å•æ­¥è§„åˆ’æ ¸å¿ƒé€»è¾‘"""
        start_time = time.time()
        messages = self._build_context_messages(user_input)

        # å¢å¼ºç³»ç»Ÿæç¤ºï¼Œå¼ºè°ƒå·¥å…·é€‰æ‹©è§„åˆ™
        enhanced_system = messages[0].get("content", "") if messages else ""

        # æ·»åŠ å¼ºåˆ¶æ€§å·¥å…·é€‰æ‹©è§„åˆ™ï¼ˆå…³é”®ï¼ï¼‰
        tool_selection_rules = """

ã€å¼ºåˆ¶æ€§å·¥å…·é€‰æ‹©è§„åˆ™ã€‘
ä½ å¿…é¡»æ ¹æ®ç”¨æˆ·è¾“å…¥çš„å…³é”®è¯é€‰æ‹©æ­£ç¡®çš„å·¥å…·ï¼š
1. å…³é”®è¯åŒ…å«"æ¸…ç†"ã€"åˆ é™¤"ã€"ç§»é™¤"ã€"æ¸…ç©º" â†’ å¿…é¡»ä½¿ç”¨ delete_tasks
2. å…³é”®è¯åŒ…å«"æŸ¥çœ‹"ã€"æ˜¾ç¤º"ã€"æœ‰ä»€ä¹ˆ"ã€"åˆ—å‡º" â†’ ä½¿ç”¨ list_tasks
3. å…³é”®è¯åŒ…å«"å®Œæˆ"ã€"åšå®Œäº†" â†’ ä½¿ç”¨ complete_task
4. å…³é”®è¯åŒ…å«"åˆ›å»º"ã€"æ·»åŠ "ã€"æé†’æˆ‘" â†’ ä½¿ç”¨ create_task

ã€Few-shot ç¤ºä¾‹ã€‘
è¾“å…¥: "å¸®æˆ‘æ¸…ç†è¿™äº›ä»»åŠ¡" â†’ å·¥å…·: delete_tasks
è¾“å…¥: "åˆ é™¤æ— æ•ˆçš„ä»»åŠ¡" â†’ å·¥å…·: delete_tasks
è¾“å…¥: "æˆ‘æœ‰ä»€ä¹ˆä»»åŠ¡" â†’ å·¥å…·: list_tasks
è¾“å…¥: "æŸ¥çœ‹å¾…åŠåˆ—è¡¨" â†’ å·¥å…·: list_tasks
è¾“å…¥: "å®Œæˆä»»åŠ¡ xxx" â†’ å·¥å…·: complete_task
è¾“å…¥: "æé†’æˆ‘æ˜å¤©å¼€ä¼š" â†’ å·¥å…·: create_task"""

        # æ›´æ–°ç³»ç»Ÿæç¤º
        for msg in messages:
            if msg.get("role") == "system":
                msg["content"] = enhanced_system + tool_selection_rules
                break

        response = await self.llm.generate_with_tools(
            messages=messages,
            tools=self.schemas,
            tool_choice="auto"
        )

        # è®°å½•æ€§èƒ½æŒ‡æ ‡
        self.metrics.record_llm_call(time.time() - start_time)
        self.metrics.record_mode("single_step")

        if response.tool_calls:
            tool_call = response.tool_calls[0]
            return ExecutionPlan(
                mode=ExecutionMode.SINGLE_STEP,
                goal=user_input,
                steps=[Step(
                    id="step_0",
                    tool_name=tool_call.name,
                    parameters=tool_call.arguments
                )]
            )
        else:
            # LLM è®¤ä¸ºä¸éœ€è¦å·¥å…·ï¼Œä½¿ç”¨ chat å·¥å…·
            return ExecutionPlan(
                mode=ExecutionMode.SINGLE_STEP,
                goal=user_input,
                steps=[Step(
                    id="step_0",
                    tool_name="chat",
                    parameters={"message": user_input}
                )]
            )

    async def _plan_multi_step_with_retry(self, user_input: str) -> ExecutionPlan:
        """å¤šæ­¥è§„åˆ’ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        for attempt in range(self.retry_attempts):
            try:
                return await self._plan_multi_step(user_input)
            except Exception as e:
                logger.warning(f"å¤šæ­¥è§„åˆ’å°è¯• {attempt + 1} å¤±è´¥: {e}")
                if attempt < self.retry_attempts - 1:
                    await asyncio.sleep(self.retry_delay * (attempt + 1))
                else:
                    logger.error(f"å¤šæ­¥è§„åˆ’æœ€ç»ˆå¤±è´¥: {e}")

        # Fallback åˆ°å•æ­¥
        return await self._plan_single_step_with_retry(user_input)

    @timed("plan_multi_step")
    async def _plan_multi_step(self, user_input: str) -> ExecutionPlan:
        """å¤šæ­¥è§„åˆ’æ ¸å¿ƒé€»è¾‘"""
        start_time = time.time()
        from datetime import datetime
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # æ„å»ºå¸¦è®°å¿†ä¸Šä¸‹æ–‡çš„è§„åˆ’æç¤º
        memory_context = ""
        if self.enable_memory_context and self.memory:
            try:
                relevant_memories = self.memory.recall(
                    query=user_input,
                    top_k=self.context_memory_limit
                )
                if relevant_memories and relevant_memories.strip():
                    memory_context = f"\nã€ç›¸å…³è®°å¿†ã€‘\n{relevant_memories}"
            except Exception as e:
                logger.warning(f"æ£€ç´¢è®°å¿†å¤±è´¥: {e}")

        # ä½¿ç”¨å¢å¼ºçš„è§„åˆ’æç¤ºè¯ï¼ˆå‚è€ƒ OpenClaw æ¶æ„ï¼‰
        prompt = f"""ã€å½“å‰æ—¶é—´ã€‘{current_time}

ã€ä»»åŠ¡åˆ†æã€‘
åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œé€‰æ‹©æ­£ç¡®çš„å·¥å…·æ‰§è¡Œä»»åŠ¡ã€‚

ã€ç”¨æˆ·è¾“å…¥ã€‘
{user_input}{memory_context}

ã€å¯ç”¨å·¥å…·ã€‘
{self._format_tools()}

ã€å·¥å…·é€‰æ‹©è§„åˆ™ã€‘ï¼ˆéå¸¸é‡è¦ï¼ï¼‰
1. "æ¸…ç†ä»»åŠ¡"ã€"åˆ é™¤ä»»åŠ¡"ã€"æ¸…ç©ºåˆ—è¡¨" â†’ å¿…é¡»ä½¿ç”¨ delete_tasks
2. "æŸ¥çœ‹ä»»åŠ¡"ã€"æœ‰ä»€ä¹ˆä»»åŠ¡"ã€"æ˜¾ç¤ºåˆ—è¡¨" â†’ ä½¿ç”¨ list_tasks
3. "å®Œæˆä»»åŠ¡"ã€"åšå®Œäº†" â†’ ä½¿ç”¨ complete_task
4. "åˆ›å»ºä»»åŠ¡"ã€"æé†’æˆ‘" â†’ ä½¿ç”¨ create_task

ã€æ­£ç¡®ç¤ºä¾‹ã€‘
ç¤ºä¾‹1:
è¾“å…¥: "å¸®æˆ‘æ¸…ç†è¿™äº›ä»»åŠ¡"
è¾“å‡º: {{"goal": "æ¸…ç†ç”¨æˆ·çš„ä»»åŠ¡åˆ—è¡¨", "steps": [{{"tool": "delete_tasks", "params": {{"delete_all": true, "confirmed": false}}, "reason": "ç”¨æˆ·è¯´æ¸…ç†ä»»åŠ¡ï¼Œéœ€è¦æ‰§è¡Œåˆ é™¤æ“ä½œ"}}]}}

ç¤ºä¾‹2:
è¾“å…¥: "åˆ é™¤æ— æ•ˆçš„ä»»åŠ¡"
è¾“å‡º: {{"goal": "åˆ é™¤æ— æ•ˆä»»åŠ¡", "steps": [{{"tool": "delete_tasks", "params": {{"confirmed": false}}, "reason": "ç”¨æˆ·è¦åˆ é™¤ä»»åŠ¡ï¼Œä½¿ç”¨ delete_tasks"}}]}}

ç¤ºä¾‹3:
è¾“å…¥: "æˆ‘æœ‰ä»€ä¹ˆå¾…åŠäº‹é¡¹"
è¾“å‡º: {{"goal": "æŸ¥çœ‹ä»»åŠ¡åˆ—è¡¨", "steps": [{{"tool": "list_tasks", "params": {{}}, "reason": "ç”¨æˆ·åªæ˜¯æƒ³æŸ¥çœ‹ï¼Œä¸æ˜¯åˆ é™¤"}}]}}

ã€é”™è¯¯ç¤ºä¾‹ã€‘âŒ
è¾“å…¥: "å¸®æˆ‘æ¸…ç†è¿™äº›ä»»åŠ¡"
é”™è¯¯è¾“å‡º: {{"goal": "æŸ¥çœ‹ä»»åŠ¡", "steps": [{{"tool": "list_tasks", ...}}]}}  // é”™è¯¯ï¼ç”¨æˆ·è¯´"æ¸…ç†"åº”è¯¥ç”¨ delete_tasks

ç°åœ¨è¯·åˆ†æç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ï¼Œè¿”å› JSON æ ¼å¼ï¼š
{{
    "goal": "ä»»åŠ¡ç›®æ ‡",
    "steps": [
        {{"tool": "å·¥å…·å", "params": {{"å‚æ•°å": "å€¼"}}, "reason": "é€‰æ‹©æ­¤å·¥å…·çš„ç†ç”±"}}
    ]
}}"""

        response = await self.llm.generate(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1  # ä½¿ç”¨ä½æ¸©åº¦ç¡®ä¿ç¨³å®šçš„å·¥å…·é€‰æ‹©å’Œ JSON è¾“å‡º
        )

        # è®°å½•æ€§èƒ½æŒ‡æ ‡
        self.metrics.record_llm_call(time.time() - start_time)
        self.metrics.record_mode("multi_step")

        # æ£€æŸ¥ç©ºå“åº”
        if not response or not response.strip():
            raise ValueError("LLM è¿”å›ç©ºå“åº”")

        # å°è¯•è§£æ JSONï¼Œå¤±è´¥æ—¶å°è¯•æå– JSON ç‰‡æ®µ
        try:
            plan_data = json.loads(response.strip())
        except json.JSONDecodeError as e:
            # å°è¯•ä»å“åº”ä¸­æå– JSON å¯¹è±¡
            import re
            json_match = re.search(r'\{[\s\S]*\}', response)
            if json_match:
                try:
                    plan_data = json.loads(json_match.group(0))
                except json.JSONDecodeError:
                    raise ValueError(f"æ— æ³•è§£æ JSON å“åº”: {response[:200]}") from e
            else:
                raise ValueError(f"å“åº”ä¸­æœªæ‰¾åˆ° JSON: {response[:200]}") from e

        return ExecutionPlan(
            mode=ExecutionMode.MULTI_STEP,
            goal=plan_data.get("goal", user_input),
            steps=[
                Step(
                    id=f"step_{i}",
                    tool_name=s["tool"],
                    parameters=s.get("params", {})
                )
                for i, s in enumerate(plan_data.get("steps", []))
            ]
        )

    # Intent åˆ°å·¥å…·åçš„æ˜ å°„è¡¨
    INTENT_TO_TOOL_MAP = {
        'chat': 'chat',
        'thanks': 'chat',
        'goodbye': 'chat',
        'help': 'chat',
        'create_task': 'create_task',
        'query_task': 'list_tasks',
        'update_task': 'complete_task',
        'delete_task': 'delete_tasks',
        'set_reminder': 'create_task',
        'create_memory': 'add_memory',
        'query_memory': 'search_memory',
        'summarize': 'summarize_memories',
        'search': 'web_search',
        'clear_history': 'clear_history',
        'switch_personality': 'switch_personality',
    }

    @timed("execute_fast_path")
    async def _execute_fast_path(self, context: AgentContext) -> AsyncGenerator[str, None]:
        """æ‰§è¡Œ Fast Path"""
        self.metrics.record_mode("fast_path")

        if not self.fast_path:
            yield "å¿«é€Ÿè·¯å¾„æœªé…ç½®\n"
            return

        start_time = time.time()
        try:
            intent = self.fast_path.classify(context.user_input)
            intent_value = intent.type.value if hasattr(intent.type, 'value') else str(intent.type)

            # ä½¿ç”¨æ˜ å°„è¡¨è·å–å·¥å…·å
            tool_name = self.INTENT_TO_TOOL_MAP.get(intent_value, 'chat')

            # æ£€æŸ¥å·¥å…·æ˜¯å¦å­˜åœ¨
            if not self.tools.has(tool_name):
                logger.warning(f"Fast path: å·¥å…· {tool_name} ä¸å­˜åœ¨ï¼Œé™çº§åˆ° chat")
                tool_name = 'chat'

            # æ ¹æ®å·¥å…·ç±»å‹ä¼ é€’æ­£ç¡®å‚æ•°
            if tool_name == "chat":
                result = await self.tools.execute(tool_name, timeout=10.0, message=context.user_input)
            else:
                result = await self.tools.execute(tool_name, timeout=30.0, **{})

            # è®°å½•æ€§èƒ½æŒ‡æ ‡
            self.metrics.record_tool_call(tool_name, time.time() - start_time, result.success)

            # å¯¹äº chat å·¥å…·ï¼Œä½¿ç”¨æµå¼ç”Ÿæˆå›å¤
            if tool_name == "chat" and self.enable_streaming:
                async for chunk in self._generate_chat_response_stream(context):
                    yield chunk
                yield "\n"
            else:
                yield result.observation + "\n"

        except Exception as e:
            logger.warning(f"Fast path å¤±è´¥: {e}")
            self.metrics.record_error(f"fast_path: {str(e)}")
            # Fallback
            async for output in self._execute_single_step(context):
                yield output

    @timed("execute_single_step")
    async def _execute_single_step(self, context: AgentContext) -> AsyncGenerator[str, None]:
        """æ‰§è¡Œå•æ­¥ï¼ˆæ”¯æŒæµå¼è¾“å‡º + æ‰§è¡Œåæ€ï¼‰"""
        step = context.plan.steps[0] if context.plan.steps else None
        if not step:
            yield "æ²¡æœ‰å¯æ‰§è¡Œçš„æ­¥éª¤\n"
            return

        step.status = "running"
        start_time = time.time()

        result = await self.tools.execute(step.tool_name, timeout=30.0, **step.parameters)

        # è®°å½•æ€§èƒ½æŒ‡æ ‡
        self.metrics.record_tool_call(step.tool_name, time.time() - start_time, result.success)

        step.result = result
        step.status = "completed" if result.success else "failed"

        if result.success:
            # æ‰§è¡Œåæ€ï¼šéªŒè¯ç»“æœæ˜¯å¦ç¬¦åˆç”¨æˆ·æ„å›¾
            retry_tool = await self._reflect_on_result(context.user_input, step.tool_name, result)
            if retry_tool:
                logger.info(f"åæ€æ£€æµ‹åˆ°éœ€è¦é‡è¯•ï¼ŒåŸå·¥å…·: {step.tool_name} -> æ–°å·¥å…·: {retry_tool}")
                # ç›´æ¥åˆ‡æ¢åˆ°æ­£ç¡®å·¥å…·ï¼Œä¸å†ä¾èµ–LLMé‡æ–°è§„åˆ’
                yield f"âš ï¸ é‡æ–°è°ƒæ•´ç­–ç•¥ï¼Œä½¿ç”¨ {retry_tool}...\n"
                new_result = await self.tools.execute(retry_tool, timeout=30.0)
                self.metrics.record_tool_call(retry_tool, time.time() - start_time, new_result.success)
                if new_result.success:
                    result = new_result
                    step.tool_name = retry_tool
                    step.result = new_result

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¡®è®¤
            if result.data and result.data.get("needs_confirmation"):
                # ä¿å­˜ç¡®è®¤çŠ¶æ€
                self._pending_confirmation = {
                    "tool_name": step.tool_name,
                    "params": step.parameters.copy()
                }
                yield result.observation + "\n"
            else:
                # å¯¹äº chat å·¥å…·ï¼Œä½¿ç”¨æµå¼ç”Ÿæˆå›å¤
                if step.tool_name == "chat" and self.enable_streaming:
                    async for chunk in self._generate_chat_response_stream(context):
                        yield chunk
                    yield "\n"
                else:
                    yield result.observation + "\n"
        else:
            yield f"æ“ä½œå¤±è´¥: {result.observation}\n"

    async def _reflect_on_result(self, user_input: str, tool_name: str, result: ToolResult) -> str | None:
        """
        æ‰§è¡Œåæ€ï¼šéªŒè¯ç»“æœæ˜¯å¦ç¬¦åˆç”¨æˆ·æ„å›¾

        Returns:
            åº”è¯¥ä½¿ç”¨çš„å·¥å…·åï¼Œæˆ– None è¡¨ç¤ºä¸éœ€è¦é‡è¯•
        """
        user_input_lower = user_input.lower()

        # åæ€è§„åˆ™ï¼šç”¨æˆ·è¯´"æ¸…ç†/åˆ é™¤"ä½†ä½¿ç”¨äº† list_tasks
        if tool_name == "list_tasks":
            delete_keywords = ["æ¸…ç†", "åˆ é™¤", "ç§»é™¤", "æ¸…ç©º", "ä¸è¦", "å»æ‰", "åˆ æ‰"]
            if any(kw in user_input_lower for kw in delete_keywords):
                logger.warning(f"åæ€: ç”¨æˆ·è¯´'{user_input}'ä½†ä½¿ç”¨äº† list_tasksï¼Œåº”ä½¿ç”¨ delete_tasks")
                return "delete_tasks"

        # åæ€è§„åˆ™ï¼šç”¨æˆ·è¯´"æŸ¥çœ‹/æ˜¾ç¤º"ä½†ä½¿ç”¨äº† delete_tasks
        if tool_name == "delete_tasks":
            view_keywords = ["æŸ¥çœ‹", "æ˜¾ç¤º", "æœ‰ä»€ä¹ˆ", "åˆ—å‡º", "çœ‹çœ‹"]
            if any(kw in user_input_lower for kw in view_keywords):
                # ä½†å¦‚æœæœ‰"æ¸…ç†"å…³é”®è¯ï¼Œåˆ™åˆ é™¤æ˜¯æ­£ç¡®çš„
                if not any(kw in user_input_lower for kw in ["æ¸…ç†", "åˆ é™¤", "ç§»é™¤"]):
                    logger.warning(f"åæ€: ç”¨æˆ·è¯´'{user_input}'ä½†ä½¿ç”¨äº† delete_tasksï¼Œåº”ä½¿ç”¨ list_tasks")
                    return "list_tasks"

        return None

    async def _generate_chat_response_stream(self, context: AgentContext) -> AsyncGenerator[str, None]:
        """æµå¼ç”ŸæˆèŠå¤©å›å¤"""
        messages = self._build_context_messages(context.user_input)

        # æµå¼ç”Ÿæˆå›å¤
        async for chunk in self._generate_response_stream(messages, temperature=0.7, max_tokens=800):
            yield chunk

    @timed("execute_multi_step")
    async def _execute_multi_step(self, context: AgentContext) -> AsyncGenerator[str, None]:
        """æ‰§è¡Œå¤šæ­¥"""
        plan = context.plan
        step_count = 0

        while not plan.is_complete and step_count < self.max_steps:
            step = plan.current
            if not step:
                break

            step.status = "running"
            yield f"  [{plan.current_step + 1}/{len(plan.steps)}] {step.tool_name}... "

            start_time = time.time()
            result = await self.tools.execute(step.tool_name, timeout=30.0, **step.parameters)

            # è®°å½•æ€§èƒ½æŒ‡æ ‡
            self.metrics.record_tool_call(step.tool_name, time.time() - start_time, result.success)

            step.result = result

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¡®è®¤
            if result.data.get("needs_confirmation"):
                step.status = "needs_clarification"
                yield f"\nğŸ’­ {result.observation}\n"
                yield {
                    "type": "need_input",
                    "prompt": "ç¡®è®¤æ‰§è¡Œå—ï¼Ÿ(yes/no/show)",
                    "context": {"step_id": step.id, "data": result.data}
                }
                return

            if result.success:
                step.status = "completed"
                yield "âœ“\n"
                if result.observation:
                    yield f"    {result.observation}\n"
            else:
                step.status = "failed"
                yield "âœ—\n"
                yield f"    é”™è¯¯: {result.observation}\n"
                self.metrics.record_error(f"{step.tool_name}: {result.observation}")

            plan.next()
            step_count += 1

    def _format_tools(self) -> str:
        """æ ¼å¼åŒ–å·¥å…·åˆ—è¡¨"""
        lines = []
        for name in self.tools.get_names():
            tool = self.tools.get(name)
            if tool:
                lines.append(f"- {name}: {tool.description}")
        return "\n".join(lines)

    def get_metrics(self) -> dict:
        """è·å–æ€§èƒ½æŒ‡æ ‡æ‘˜è¦"""
        return self.metrics.get_summary()

    def reset_metrics(self):
        """é‡ç½®æ€§èƒ½æŒ‡æ ‡"""
        self.metrics = MetricsCollector()

    async def continue_with_input(
        self,
        user_input: str,
        context: AgentContext
    ) -> AsyncGenerator[str, None]:
        """
        ç»§ç»­æ‰§è¡Œï¼ˆç”¨æˆ·è¾“å…¥ç¡®è®¤åï¼‰

        Args:
            user_input: ç”¨æˆ·è¾“å…¥ï¼ˆå¦‚ "yes"ï¼‰
            context: å½“å‰ä¸Šä¸‹æ–‡
        """
        plan = context.plan
        step = plan.current if plan else None

        if not step:
            yield "æ²¡æœ‰å¾…æ‰§è¡Œçš„æ­¥éª¤\n"
            return

        if user_input.lower() in ["yes", "y", "ç¡®è®¤", "æ˜¯"]:
            # ç»§ç»­æ‰§è¡Œ
            step.parameters["confirmed"] = True
            result = await self.tools.execute(step.tool_name, timeout=30.0, **step.parameters)

            if result.success:
                yield f"âœ… {result.observation}\n"
                plan.next()

                # ç»§ç»­åç»­æ­¥éª¤
                if not plan.is_complete:
                    async for output in self._execute_multi_step(context):
                        yield output
            else:
                yield f"âŒ {result.observation}\n"

        elif user_input.lower() in ["no", "n", "å–æ¶ˆ", "å¦"]:
            yield "å·²å–æ¶ˆæ“ä½œ\n"
            step.status = "cancelled"
            plan.next()

        else:
            yield "è¯·è¾“å…¥ yes ç¡®è®¤æˆ– no å–æ¶ˆ\n"
