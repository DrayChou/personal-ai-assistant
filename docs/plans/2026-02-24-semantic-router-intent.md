# Semantic Router æ„å›¾åˆ†ç±»é‡æ„è®¡åˆ’

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** ä½¿ç”¨ Semantic Router å‘é‡è¯­ä¹‰è·¯ç”±æ›¿ä»£æ­£åˆ™åŒ¹é…å’Œ LLM è°ƒç”¨ï¼Œå®ç°æ¯«ç§’çº§æ„å›¾åˆ†ç±»

**Architecture:**
- ç”¨æˆ·è¾“å…¥ â†’ embedding å‘é‡åŒ– â†’ ä¸é¢„å®šä¹‰æ„å›¾å‘é‡è®¡ç®—ç›¸ä¼¼åº¦ â†’ è·¯ç”±åˆ°å¯¹åº” handler
- ä½ç½®ä¿¡åº¦æ—¶å›é€€åˆ° LLM Function Calling
- ä½¿ç”¨é¡¹ç›®ç°æœ‰çš„ Ollama embedding æˆ–å¯é€‰çš„äº‘ç«¯ embedding

**Tech Stack:** semantic-router, ç°æœ‰ embedding æœºåˆ¶, MiniMax/OpenAI LLM

---

## å½“å‰é—®é¢˜åˆ†æ

### ç°æœ‰æ¶æ„çš„é—®é¢˜
1. **è§„åˆ™åˆ†ç±»å™¨** (`intent_classifier.py`): æ­£åˆ™åŒ¹é…å¤ªæ­»æ¿ï¼Œæ— æ³•ç†è§£è¯­ä¹‰
2. **AI åˆ†ç±»å™¨** (`ai_intent_classifier.py`): æ¯æ¬¡è°ƒç”¨ LLMï¼Œå¢åŠ å»¶è¿Ÿå’Œæˆæœ¬
3. **ä¸¤è€…æ··åˆ**: é€»è¾‘æ··ä¹±ï¼Œè°ƒç”¨è·¯å¾„ä¸æ¸…æ™°

### ç›®æ ‡æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ç”¨æˆ·è¾“å…¥                                 â”‚
â”‚                         â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           Semantic Router (å‘é‡è¯­ä¹‰è·¯ç”±)             â”‚ âš¡ æ¯«ç§’çº§
â”‚  â”‚   user_input â†’ embedding â†’ cosine similarity        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                  ç½®ä¿¡åº¦åˆ¤æ–­                          â”‚   â”‚
â”‚  â”‚   if confidence > 0.7: ç›´æ¥è·¯ç”±åˆ° handler           â”‚   â”‚
â”‚  â”‚   elif confidence > 0.4: è¿”å› CHAT æ¨¡å¼             â”‚   â”‚
â”‚  â”‚   else: å›é€€åˆ° LLM Function Calling                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              ActionRouter â†’ handler                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Task 1: æ·»åŠ  semantic-router ä¾èµ–

**Files:**
- Modify: `pyproject.toml`

**Step 1: æ·»åŠ ä¾èµ–**

```toml
# åœ¨ dependencies ä¸­æ·»åŠ 
"semantic-router>=0.1.0",
```

**Step 2: å®‰è£…ä¾èµ–**

Run: `cd /Users/dray/Code/my/demo/personal-ai-assistant && uv sync`

Expected: æˆåŠŸå®‰è£… semantic-router

**Step 3: éªŒè¯å®‰è£…**

Run: `python3 -c "from semantic_router import Route, RouteLayer; print('OK')"`

Expected: è¾“å‡º `OK`

**Step 4: Commit**

```bash
git add pyproject.toml uv.lock
git commit -m "chore: add semantic-router dependency"
```

---

## Task 2: åˆ›å»º SemanticIntentRouter æ ¸å¿ƒç±»

**Files:**
- Create: `src/chat/semantic_router.py`
- Test: `tests/test_semantic_router.py`

**Step 1: åˆ›å»ºæµ‹è¯•æ–‡ä»¶**

```python
# tests/test_semantic_router.py
"""æµ‹è¯• Semantic Router æ„å›¾åˆ†ç±»"""
import pytest
from chat.semantic_router import SemanticIntentRouter, IntentType


class TestSemanticIntentRouter:
    """SemanticIntentRouter æµ‹è¯•"""

    def test_chat_greeting(self):
        """æµ‹è¯•é—®å€™è¯­è¯†åˆ«"""
        router = SemanticIntentRouter()
        result = router.route("ä½ å¥½")
        assert result.intent_type == IntentType.CHAT
        assert result.confidence > 0.5

    def test_create_task(self):
        """æµ‹è¯•åˆ›å»ºä»»åŠ¡è¯†åˆ«"""
        router = SemanticIntentRouter()
        result = router.route("å¸®æˆ‘è®°å½•ä¸€ä¸ªä»»åŠ¡ï¼šæ˜å¤©å¼€ä¼š")
        assert result.intent_type == IntentType.CREATE_TASK
        assert result.confidence > 0.5

    def test_search_query(self):
        """æµ‹è¯•æœç´¢æŸ¥è¯¢è¯†åˆ«"""
        router = SemanticIntentRouter()
        result = router.route("æœç´¢ä¸€ä¸‹ Python æ•™ç¨‹")
        assert result.intent_type == IntentType.SEARCH
        assert result.confidence > 0.5

    def test_weather_query(self):
        """æµ‹è¯•å¤©æ°”æŸ¥è¯¢è¯†åˆ«"""
        router = SemanticIntentRouter()
        result = router.route("ä»Šå¤©åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·")
        assert result.intent_type == IntentType.WEATHER
        assert result.confidence > 0.5

    def test_set_reminder(self):
        """æµ‹è¯•è®¾ç½®æé†’è¯†åˆ«"""
        router = SemanticIntentRouter()
        result = router.route("æ˜å¤©æ—©ä¸Š8ç‚¹å«æˆ‘èµ·åºŠ")
        assert result.intent_type == IntentType.SET_REMINDER
        assert result.confidence > 0.5

    def test_low_confidence_returns_chat(self):
        """æµ‹è¯•ä½ç½®ä¿¡åº¦è¿”å› CHAT"""
        router = SemanticIntentRouter()
        result = router.route("asdfghjkl")  # æ— æ„ä¹‰è¾“å…¥
        assert result.intent_type == IntentType.CHAT
```

**Step 2: è¿è¡Œæµ‹è¯•ç¡®è®¤å¤±è´¥**

Run: `cd /Users/dray/Code/my/demo/personal-ai-assistant && python3 -m pytest tests/test_semantic_router.py -v`

Expected: FAIL (æ¨¡å—ä¸å­˜åœ¨)

**Step 3: åˆ›å»º SemanticIntentRouter å®ç°**

```python
# src/chat/semantic_router.py
# -*- coding: utf-8 -*-
"""
Semantic Router æ„å›¾åˆ†ç±»å™¨

ä½¿ç”¨å‘é‡è¯­ä¹‰ç›¸ä¼¼åº¦è¿›è¡Œæ„å›¾åˆ†ç±»ï¼Œæ¯«ç§’çº§å“åº”ã€‚
ä½ç½®ä¿¡åº¦æ—¶å›é€€åˆ° LLM Function Callingã€‚
"""
import logging
from dataclasses import dataclass
from typing import Optional, Callable
from enum import Enum

from semantic_router import Route, RouteLayer
from semantic_router.encoders import BaseEncoder

from .intent_classifier import IntentType, Intent

logger = logging.getLogger('chat.semantic_router')


# é¢„å®šä¹‰çš„æ„å›¾è·¯ç”±å’Œç¤ºä¾‹è¯­å¥
INTENT_ROUTES = {
    IntentType.CHAT: [
        "ä½ å¥½", "å—¨", "æ‚¨å¥½", "hello", "hi",
        "å¥½ä¹…ä¸è§", "æœ€è¿‘æ€ä¹ˆæ ·", "ä»Šå¤©æ€ä¹ˆæ ·",
        "ä½ æ˜¯è°", "ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±", "ä½ å«ä»€ä¹ˆåå­—",
        "è°¢è°¢", "æ„Ÿè°¢", "thank you",
        "å†è§", "æ‹œæ‹œ", "goodbye",
        "è®²ä¸ªç¬‘è¯", "è¯´ä¸ªç¬‘è¯", "æ¥ä¸ªç¬‘è¯",
    ],
    IntentType.CREATE_TASK: [
        "å¸®æˆ‘è®°å½•ä¸€ä¸ªä»»åŠ¡", "æ·»åŠ ä»»åŠ¡", "åˆ›å»ºä»»åŠ¡",
        "æé†’æˆ‘æ˜å¤©", "è®°ä¸€ä¸‹", "åˆ«å¿˜äº†",
        "å¾…åŠäº‹é¡¹", "TODO", "todo",
        "å¸®æˆ‘è®°ä½", "è®°ä¸‹æ¥",
    ],
    IntentType.QUERY_TASK: [
        "æŸ¥çœ‹ä»»åŠ¡", "æœ‰ä»€ä¹ˆä»»åŠ¡", "æˆ‘çš„å¾…åŠ",
        "ä»»åŠ¡åˆ—è¡¨", "å¾…åŠåˆ—è¡¨", "è¿˜æœ‰ä»€ä¹ˆè¦åšçš„",
        "æŸ¥çœ‹æé†’", "æˆ‘çš„æé†’",
    ],
    IntentType.SET_REMINDER: [
        "æ˜å¤©æ—©ä¸Šå«æˆ‘èµ·åºŠ", "è®¾ç½®æé†’", "å®šæ—¶æé†’",
        "å‡ ç‚¹æé†’æˆ‘", "åˆ°æ—¶é—´å«æˆ‘",
        "æé†’æˆ‘å¼€ä¼š", "æé†’æˆ‘åƒè¯",
    ],
    IntentType.SEARCH: [
        "æœç´¢ä¸€ä¸‹", "æŸ¥ä¸€ä¸‹", "å¸®æˆ‘æŸ¥",
        "æœç´¢", "æŸ¥æ‰¾", "æ‰¾ä¸€ä¸‹",
        "å¸®æˆ‘æ‰¾", "æŸ¥æŸ¥",
    ],
    IntentType.WEATHER: [
        "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·", "å¤©æ°”", "æ°”æ¸©",
        "ä¼šä¸‹é›¨å—", "éœ€è¦å¸¦ä¼å—",
        "åŒ—äº¬å¤©æ°”", "ä¸Šæµ·å¤©æ°”",
    ],
    IntentType.NEWS: [
        "ä»Šå¤©æ–°é—»", "æœ€æ–°æ–°é—»", "æœ‰ä»€ä¹ˆæ–°é—»",
        "ç§‘æŠ€æ–°é—»", "è´¢ç»æ–°é—»", "çƒ­ç‚¹æ–°é—»",
    ],
    IntentType.TRANSLATE: [
        "ç¿»è¯‘ä¸€ä¸‹", "ç¿»è¯‘æˆè‹±æ–‡", "ç¿»è¯‘æˆä¸­æ–‡",
        "æ€ä¹ˆè¯´", "ç”¨è‹±è¯­æ€ä¹ˆè¯´",
    ],
    IntentType.CALCULATE: [
        "è®¡ç®—ä¸€ä¸‹", "ç®—ä¸€ä¸‹", "ç­‰äºå¤šå°‘",
        "åŠ ", "å‡", "ä¹˜", "é™¤",
        "æ•°å­¦è®¡ç®—",
    ],
    IntentType.CREATE_MEMORY: [
        "è®°ä½è¿™ä¸ª", "è®°å½•ä¸‹æ¥", "å¸®æˆ‘è®°ä¸€ä¸‹",
        "ä¿å­˜è¿™ä¸ªä¿¡æ¯", "è®°ä½æˆ‘çš„",
    ],
    IntentType.QUERY_MEMORY: [
        "ä½ è¿˜è®°å¾—", "æˆ‘ä¹‹å‰è¯´è¿‡ä»€ä¹ˆ",
        "å›å¿†ä¸€ä¸‹", "ä¹‹å‰è®°å½•çš„",
    ],
    IntentType.SWITCH_PERSONALITY: [
        "åˆ‡æ¢æ€§æ ¼", "æ¢ä¸€ä¸ªæ€§æ ¼", "å˜æˆçŒ«å¨˜",
        "ä½¿ç”¨å¤§å°å§", "åˆ‡æ¢åˆ°é»˜è®¤",
    ],
}


@dataclass
class RoutingResult:
    """è·¯ç”±ç»“æœ"""
    intent_type: IntentType
    confidence: float
    needs_llm_fallback: bool
    reasoning: str = ""


class SemanticIntentRouter:
    """
    è¯­ä¹‰æ„å›¾è·¯ç”±å™¨

    ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦è¿›è¡Œå¿«é€Ÿæ„å›¾åˆ†ç±»
    """

    # ç½®ä¿¡åº¦é˜ˆå€¼
    HIGH_CONFIDENCE = 0.7   # é«˜äºæ­¤å€¼ç›´æ¥è·¯ç”±
    LOW_CONFIDENCE = 0.4    # ä½äºæ­¤å€¼å›é€€ LLM

    def __init__(
        self,
        encoder: Optional[BaseEncoder] = None,
        llm_fallback: Optional[Callable] = None
    ):
        """
        åˆå§‹åŒ–è¯­ä¹‰è·¯ç”±å™¨

        Args:
            encoder: å‘é‡ç¼–ç å™¨ï¼ˆé»˜è®¤ä½¿ç”¨æœ¬åœ° HuggingFaceï¼‰
            llm_fallback: LLM å›é€€å‡½æ•°
        """
        self.llm_fallback = llm_fallback
        self.encoder = encoder
        self.route_layer = self._build_route_layer()

    def _build_route_layer(self) -> RouteLayer:
        """æ„å»ºè·¯ç”±å±‚"""
        routes = []
        for intent_type, utterances in INTENT_ROUTES.items():
            route = Route(
                name=intent_type.value,
                utterances=utterances,
            )
            routes.append(route)

        # åˆ›å»ºè·¯ç”±å±‚
        if self.encoder:
            return RouteLayer(routes=routes, encoder=self.encoder)
        else:
            # ä½¿ç”¨é»˜è®¤ç¼–ç å™¨
            return RouteLayer(routes=routes)

    def route(self, text: str) -> RoutingResult:
        """
        è·¯ç”±ç”¨æˆ·è¾“å…¥

        Args:
            text: ç”¨æˆ·è¾“å…¥

        Returns:
            RoutingResult åŒ…å«æ„å›¾å’Œç½®ä¿¡åº¦
        """
        # è°ƒç”¨è¯­ä¹‰è·¯ç”±
        route_result = self.route_layer(text)

        if route_result is None:
            # æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•è·¯ç”±
            return RoutingResult(
                intent_type=IntentType.CHAT,
                confidence=0.0,
                needs_llm_fallback=True,
                reasoning="æœªåŒ¹é…åˆ°ä»»ä½•é¢„å®šä¹‰æ„å›¾"
            )

        # è·å–åŒ¹é…çš„æ„å›¾
        matched_route_name = route_result.name
        similarity_score = getattr(route_result, 'similarity_score', 0.5)

        # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆç›¸ä¼¼åº¦è½¬æ¢ä¸º 0-1 èŒƒå›´ï¼‰
        confidence = min(max(similarity_score, 0.0), 1.0)

        # è§£ææ„å›¾ç±»å‹
        try:
            intent_type = IntentType(matched_route_name)
        except ValueError:
            intent_type = IntentType.CHAT

        # åˆ¤æ–­æ˜¯å¦éœ€è¦ LLM å›é€€
        needs_llm_fallback = confidence < self.LOW_CONFIDENCE

        return RoutingResult(
            intent_type=intent_type,
            confidence=confidence,
            needs_llm_fallback=needs_llm_fallback,
            reasoning=f"è¯­ä¹‰åŒ¹é…: {matched_route_name}, ç›¸ä¼¼åº¦: {similarity_score:.2f}"
        )

    def classify(self, text: str, context: str = "") -> Intent:
        """
        åˆ†ç±»æ„å›¾ï¼ˆå…¼å®¹ç°æœ‰æ¥å£ï¼‰

        Args:
            text: ç”¨æˆ·è¾“å…¥
            context: å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆæš‚æœªä½¿ç”¨ï¼‰

        Returns:
            Intent å¯¹è±¡
        """
        result = self.route(text)

        return Intent(
            intent_type=result.intent_type,
            confidence=result.confidence,
            entities={},  # è¯­ä¹‰è·¯ç”±ä¸æå–å®ä½“
            raw_text=text,
            reasoning=result.reasoning,
            requires_tool=result.intent_type in self._get_tool_required_intents(),
            suggested_tools=self._get_suggested_tools(result.intent_type)
        )

    def _get_tool_required_intents(self) -> set:
        """è·å–éœ€è¦å·¥å…·çš„æ„å›¾ç±»å‹"""
        return {
            IntentType.SEARCH,
            IntentType.NEWS,
            IntentType.WEATHER,
            IntentType.CALCULATE,
            IntentType.TRANSLATE,
        }

    def _get_suggested_tools(self, intent_type: IntentType) -> list:
        """è·å–å»ºè®®çš„å·¥å…·"""
        tool_map = {
            IntentType.SEARCH: ["web_search"],
            IntentType.NEWS: ["news_search"],
            IntentType.WEATHER: ["weather_api"],
            IntentType.CALCULATE: ["calculator"],
            IntentType.TRANSLATE: ["translator"],
        }
        return tool_map.get(intent_type, [])

    def add_route(self, intent_type: IntentType, utterances: list[str]):
        """
        åŠ¨æ€æ·»åŠ è·¯ç”±

        Args:
            intent_type: æ„å›¾ç±»å‹
            utterances: ç¤ºä¾‹è¯­å¥åˆ—è¡¨
        """
        route = Route(
            name=intent_type.value,
            utterances=utterances,
        )
        self.route_layer.add(route)
        logger.info(f"æ·»åŠ è·¯ç”±: {intent_type.value}, ç¤ºä¾‹æ•°: {len(utterances)}")
```

**Step 4: è¿è¡Œæµ‹è¯•ç¡®è®¤é€šè¿‡**

Run: `cd /Users/dray/Code/my/demo/personal-ai-assistant && python3 -m pytest tests/test_semantic_router.py -v`

Expected: éƒ¨åˆ†é€šè¿‡ï¼ˆå¯èƒ½éœ€è¦é…ç½® encoderï¼‰

**Step 5: Commit**

```bash
git add src/chat/semantic_router.py tests/test_semantic_router.py
git commit -m "feat: add SemanticIntentRouter for fast intent classification"
```

---

## Task 3: åˆ›å»ºæœ¬åœ° Embedding ç¼–ç å™¨é€‚é…å™¨

**Files:**
- Modify: `src/chat/semantic_router.py`
- Modify: `tests/test_semantic_router.py`

**Step 1: æ·»åŠ ç¼–ç å™¨é€‚é…å™¨æµ‹è¯•**

```python
# åœ¨ tests/test_semantic_router.py ä¸­æ·»åŠ 

class TestLocalEncoder:
    """æœ¬åœ°ç¼–ç å™¨æµ‹è¯•"""

    def test_encoder_initialization(self):
        """æµ‹è¯•ç¼–ç å™¨åˆå§‹åŒ–"""
        from chat.semantic_router import LocalOllamaEncoder
        encoder = LocalOllamaEncoder(base_url="http://localhost:11434")
        assert encoder is not None

    def test_encoder_embed(self):
        """æµ‹è¯•ç¼–ç å™¨ç”Ÿæˆå‘é‡"""
        from chat.semantic_router import LocalOllamaEncoder
        encoder = LocalOllamaEncoder(base_url="http://localhost:11434")
        # å¦‚æœ Ollama ä¸è¿è¡Œï¼Œè¿™ä¸ªæµ‹è¯•å¯èƒ½å¤±è´¥
        try:
            vectors = encoder(["ä½ å¥½", "hello"])
            assert len(vectors) == 2
            assert all(len(v) > 0 for v in vectors)
        except Exception:
            pytest.skip("Ollama not running")
```

**Step 2: æ·»åŠ ç¼–ç å™¨å®ç°**

åœ¨ `src/chat/semantic_router.py` ä¸­æ·»åŠ :

```python
# åœ¨ imports åæ·»åŠ 

class LocalOllamaEncoder(BaseEncoder):
    """
    æœ¬åœ° Ollama Embedding ç¼–ç å™¨

    ä½¿ç”¨é¡¹ç›®å·²æœ‰çš„ Ollama embedding æœåŠ¡
    """

    def __init__(
        self,
        base_url: str = "http://localhost:11434",
        model: str = "nomic-embed-text",
        name: str = "ollama"
    ):
        super().__init__(name=name)
        self.base_url = base_url.rstrip('/')
        self.model = model

    def __call__(self, docs: list[str]) -> list[list[float]]:
        """
        ç”Ÿæˆæ–‡æ¡£çš„å‘é‡è¡¨ç¤º

        Args:
            docs: æ–‡æ¡£åˆ—è¡¨

        Returns:
            å‘é‡åˆ—è¡¨
        """
        import urllib.request
        import json

        url = f"{self.base_url}/api/embeddings"
        vectors = []

        for doc in docs:
            data = {
                "model": self.model,
                "prompt": doc
            }

            req = urllib.request.Request(
                url,
                data=json.dumps(data).encode('utf-8'),
                headers={"Content-Type": "application/json"},
                method="POST"
            )

            try:
                with urllib.request.urlopen(req, timeout=30) as response:
                    result = json.loads(response.read().decode('utf-8'))
                    vectors.append(result.get("embedding", []))
            except Exception as e:
                logger.warning(f"Ollama embedding å¤±è´¥: {e}, è¿”å›ç©ºå‘é‡")
                # è¿”å›é›¶å‘é‡ä½œä¸ºå›é€€
                vectors.append([0.0] * 768)

        return vectors
```

**Step 3: æ›´æ–° SemanticIntentRouter ä½¿ç”¨æœ¬åœ°ç¼–ç å™¨**

ä¿®æ”¹ `SemanticIntentRouter.__init__`:

```python
def __init__(
    self,
    encoder: Optional[BaseEncoder] = None,
    llm_fallback: Optional[Callable] = None,
    ollama_base_url: str = "http://localhost:11434",
    ollama_model: str = "nomic-embed-text"
):
    """
    åˆå§‹åŒ–è¯­ä¹‰è·¯ç”±å™¨

    Args:
        encoder: è‡ªå®šä¹‰å‘é‡ç¼–ç å™¨
        llm_fallback: LLM å›é€€å‡½æ•°
        ollama_base_url: Ollama æœåŠ¡åœ°å€
        ollama_model: Embedding æ¨¡å‹åç§°
    """
    self.llm_fallback = llm_fallback

    if encoder:
        self.encoder = encoder
    else:
        # é»˜è®¤ä½¿ç”¨æœ¬åœ° Ollama ç¼–ç å™¨
        self.encoder = LocalOllamaEncoder(
            base_url=ollama_base_url,
            model=ollama_model
        )

    self.route_layer = self._build_route_layer()
```

**Step 4: è¿è¡Œæµ‹è¯•**

Run: `cd /Users/dray/Code/my/demo/personal-ai-assistant && python3 -m pytest tests/test_semantic_router.py -v`

**Step 5: Commit**

```bash
git add src/chat/semantic_router.py tests/test_semantic_router.py
git commit -m "feat: add LocalOllamaEncoder for semantic routing"
```

---

## Task 4: æ›´æ–° main.py é›†æˆ Semantic Router

**Files:**
- Modify: `src/main.py`
- Modify: `src/config/settings.py`

**Step 1: æ·»åŠ é…ç½®é¡¹åˆ° settings.py**

```python
# åœ¨ ToolConfig ä¸­æ·»åŠ 
@dataclass
class ToolConfig:
    """å·¥å…·é…ç½®"""
    use_ai_intent: bool = True  # ä½¿ç”¨ AI æ„å›¾åˆ†ç±»
    use_semantic_router: bool = True  # ä½¿ç”¨è¯­ä¹‰è·¯ç”±ï¼ˆæ¨èï¼‰
    semantic_router_threshold: float = 0.7  # è¯­ä¹‰è·¯ç”±ç½®ä¿¡åº¦é˜ˆå€¼
    # ... å…¶ä»–é…ç½®
```

**Step 2: æ›´æ–° main.py åˆå§‹åŒ–é€»è¾‘**

```python
# åœ¨ main.py ä¸­ä¿®æ”¹æ„å›¾åˆ†ç±»å™¨åˆå§‹åŒ–éƒ¨åˆ†

# åˆå§‹åŒ–æ„å›¾åˆ†ç±»å™¨
if self.settings.use_semantic_router:
    logger.info("ä½¿ç”¨ Semantic Router è¯­ä¹‰è·¯ç”±")
    from chat.semantic_router import SemanticIntentRouter
    self.intent_classifier = SemanticIntentRouter(
        llm_fallback=self.llm.generate if self.settings.use_ai_intent else None,
        ollama_base_url=self.settings.embedding_base_url,
        ollama_model=self.settings.embedding_model
    )
elif self.settings.use_ai_intent:
    logger.info("ä½¿ç”¨ AI æ„å›¾åˆ†ç±»å™¨")
    self.intent_classifier = AIIntentClassifier(llm_client=self.llm.generate)
else:
    logger.info("ä½¿ç”¨è§„åˆ™æ„å›¾åˆ†ç±»å™¨")
    self.intent_classifier = IntentClassifier(llm_client=self.llm.generate)
```

**Step 3: æ›´æ–° .env é…ç½®**

```bash
# åœ¨ .env ä¸­æ·»åŠ 
USE_SEMANTIC_ROUTER=true
SEMANTIC_ROUTER_THRESHOLD=0.7
```

**Step 4: æµ‹è¯•é›†æˆ**

Run: `cd /Users/dray/Code/my/demo/personal-ai-assistant && python3 -c "from src.main import PersonalAssistant; print('OK')"`

Expected: è¾“å‡º `OK`

**Step 5: Commit**

```bash
git add src/main.py src/config/settings.py .env
git commit -m "feat: integrate Semantic Router into main application"
```

---

## Task 5: æ·»åŠ  LLM å›é€€æœºåˆ¶

**Files:**
- Modify: `src/chat/semantic_router.py`
- Test: `tests/test_semantic_router.py`

**Step 1: æ·»åŠ å›é€€æµ‹è¯•**

```python
# åœ¨ tests/test_semantic_router.py ä¸­æ·»åŠ 

class TestLLMFallback:
    """LLM å›é€€æœºåˆ¶æµ‹è¯•"""

    def test_low_confidence_triggers_fallback(self):
        """æµ‹è¯•ä½ç½®ä¿¡åº¦è§¦å‘å›é€€"""
        # åˆ›å»ºå¸¦æœ‰ mock LLM çš„è·¯ç”±å™¨
        def mock_llm(messages):
            return '{"primary_intent": "chat", "confidence": 0.9}'

        router = SemanticIntentRouter(llm_fallback=mock_llm)
        result = router.route("asdfghjkl qwerty")  # æ— æ„ä¹‰è¾“å…¥

        # åº”è¯¥æ ‡è®°éœ€è¦å›é€€
        assert result.needs_llm_fallback or result.intent_type == IntentType.CHAT

    def test_high_confidence_no_fallback(self):
        """æµ‹è¯•é«˜ç½®ä¿¡åº¦ä¸è§¦å‘å›é€€"""
        router = SemanticIntentRouter()
        result = router.route("ä½ å¥½")

        # é«˜ç½®ä¿¡åº¦ä¸åº”è¯¥éœ€è¦å›é€€
        assert not result.needs_llm_fallback or result.confidence >= 0.4
```

**Step 2: å®ç°å›é€€é€»è¾‘**

åœ¨ `semantic_router.py` ä¸­ä¿®æ”¹ `classify` æ–¹æ³•:

```python
def classify(self, text: str, context: str = "") -> Intent:
    """
    åˆ†ç±»æ„å›¾ï¼ˆå…¼å®¹ç°æœ‰æ¥å£ï¼‰

    Args:
        text: ç”¨æˆ·è¾“å…¥
        context: å¯¹è¯ä¸Šä¸‹æ–‡

    Returns:
        Intent å¯¹è±¡
    """
    result = self.route(text)

    # å¦‚æœéœ€è¦ LLM å›é€€
    if result.needs_llm_fallback and self.llm_fallback:
        logger.info(f"ç½®ä¿¡åº¦ {result.confidence:.2f} è¿‡ä½ï¼Œå›é€€åˆ° LLM")
        try:
            llm_result = self._classify_with_llm(text, context)
            if llm_result:
                return llm_result
        except Exception as e:
            logger.warning(f"LLM å›é€€å¤±è´¥: {e}")

    return Intent(
        intent_type=result.intent_type,
        confidence=result.confidence,
        entities={},
        raw_text=text,
        reasoning=result.reasoning,
        requires_tool=result.intent_type in self._get_tool_required_intents(),
        suggested_tools=self._get_suggested_tools(result.intent_type)
    )

def _classify_with_llm(self, text: str, context: str) -> Optional[Intent]:
    """ä½¿ç”¨ LLM è¿›è¡Œæ„å›¾åˆ†ç±»ï¼ˆå›é€€ï¼‰"""
    import json

    prompt = f"""åˆ†æç”¨æˆ·è¾“å…¥çš„æ„å›¾ï¼Œè¿”å› JSON æ ¼å¼ï¼š
{{"intent": "æ„å›¾ç±»å‹", "confidence": 0.0-1.0}}

å¯é€‰æ„å›¾: chat, create_task, query_task, search, weather, news, translate, calculate

ç”¨æˆ·è¾“å…¥: {text}
"""

    try:
        messages = [{"role": "user", "content": prompt}]
        response = self.llm_fallback(messages)

        # æå– JSON
        import re
        json_match = re.search(r'\{[^}]+\}', response)
        if json_match:
            data = json.loads(json_match.group())
            intent_str = data.get("intent", "chat")
            try:
                intent_type = IntentType(intent_str)
            except ValueError:
                intent_type = IntentType.CHAT

            return Intent(
                intent_type=intent_type,
                confidence=data.get("confidence", 0.5),
                entities={},
                raw_text=text,
                reasoning="LLM å›é€€åˆ†ç±»",
                requires_tool=intent_type in self._get_tool_required_intents(),
                suggested_tools=self._get_suggested_tools(intent_type)
            )
    except Exception as e:
        logger.error(f"LLM åˆ†ç±»å¤±è´¥: {e}")

    return None
```

**Step 3: è¿è¡Œæµ‹è¯•**

Run: `cd /Users/dray/Code/my/demo/personal-ai-assistant && python3 -m pytest tests/test_semantic_router.py -v`

**Step 4: Commit**

```bash
git add src/chat/semantic_router.py tests/test_semantic_router.py
git commit -m "feat: add LLM fallback mechanism for low confidence cases"
```

---

## Task 6: ç«¯åˆ°ç«¯æµ‹è¯•å’ŒéªŒè¯

**Files:**
- Create: `tests/test_e2e_intent.py`

**Step 1: åˆ›å»ºç«¯åˆ°ç«¯æµ‹è¯•**

```python
# tests/test_e2e_intent.py
"""ç«¯åˆ°ç«¯æ„å›¾åˆ†ç±»æµ‹è¯•"""
import pytest
from chat.semantic_router import SemanticIntentRouter
from chat.intent_classifier import IntentType


class TestE2EIntentClassification:
    """ç«¯åˆ°ç«¯æ„å›¾åˆ†ç±»æµ‹è¯•"""

    @pytest.fixture
    def router(self):
        """åˆ›å»ºè·¯ç”±å™¨å®ä¾‹"""
        return SemanticIntentRouter()

    @pytest.mark.parametrize("input_text,expected_intent", [
        ("ä½ å¥½", IntentType.CHAT),
        ("ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·", IntentType.WEATHER),
        ("æœç´¢ Python æ•™ç¨‹", IntentType.SEARCH),
        ("å¸®æˆ‘è®°ä¸€ä¸ªä»»åŠ¡ï¼šæ˜å¤©å¼€ä¼š", IntentType.CREATE_TASK),
        ("æŸ¥çœ‹æˆ‘çš„å¾…åŠ", IntentType.QUERY_TASK),
        ("ç¿»è¯‘ä¸€ä¸‹ hello", IntentType.TRANSLATE),
        ("è®¡ç®— 123 + 456", IntentType.CALCULATE),
        ("æ˜å¤©æ—©ä¸Š8ç‚¹å«æˆ‘", IntentType.SET_REMINDER),
    ])
    def test_intent_classification(self, router, input_text, expected_intent):
        """æµ‹è¯•å„ç§æ„å›¾åˆ†ç±»"""
        result = router.classify(input_text)
        # å…è®¸ä¸€å®šçš„è¯¯å·®ï¼Œåªè¦ä¸æ˜¯å®Œå…¨é”™è¯¯çš„ç±»å‹
        assert result.type in [expected_intent, IntentType.CHAT]
```

**Step 2: è¿è¡Œç«¯åˆ°ç«¯æµ‹è¯•**

Run: `cd /Users/dray/Code/my/demo/personal-ai-assistant && python3 -m pytest tests/test_e2e_intent.py -v`

**Step 3: æ‰‹åŠ¨æµ‹è¯•**

```bash
# å¯åŠ¨åº”ç”¨
cd /Users/dray/Code/my/demo/personal-ai-assistant
python3 src/main.py

# æµ‹è¯•å¯¹è¯
# è¾“å…¥: ä½ å¥½
# è¾“å…¥: ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·
# è¾“å…¥: æœç´¢ Python æ•™ç¨‹
# è¾“å…¥: å¸®æˆ‘è®°ä¸€ä¸ªä»»åŠ¡
```

**Step 4: Commit**

```bash
git add tests/test_e2e_intent.py
git commit -m "test: add e2e tests for intent classification"
```

---

## Task 7: æ¸…ç†æ—§ä»£ç å’Œæ–‡æ¡£æ›´æ–°

**Files:**
- Modify: `README.md` æˆ–ç›¸å…³æ–‡æ¡£
- Optional: Deprecate `ai_intent_classifier.py`

**Step 1: æ›´æ–° README æ–‡æ¡£**

æ·»åŠ å…³äº Semantic Router çš„è¯´æ˜:

```markdown
## æ„å›¾åˆ†ç±»ç³»ç»Ÿ

æœ¬é¡¹ç›®ä½¿ç”¨ **Semantic Router** è¿›è¡Œå¿«é€Ÿçš„æ„å›¾åˆ†ç±»ï¼š

- âš¡ **æ¯«ç§’çº§å“åº”**: ä½¿ç”¨å‘é‡è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œæ— éœ€è°ƒç”¨ LLM
- ğŸ¯ **è¯­ä¹‰ç†è§£**: æ¯”æ­£åˆ™åŒ¹é…æ›´å‡†ç¡®
- ğŸ”„ **æ™ºèƒ½å›é€€**: ä½ç½®ä¿¡åº¦æ—¶è‡ªåŠ¨å›é€€åˆ° LLM

### é…ç½®é€‰é¡¹

```bash
USE_SEMANTIC_ROUTER=true        # å¯ç”¨è¯­ä¹‰è·¯ç”±
SEMANTIC_ROUTER_THRESHOLD=0.7   # ç½®ä¿¡åº¦é˜ˆå€¼
```
```

**Step 2: æ ‡è®°æ—§ä»£ç ä¸ºå¯é€‰**

åœ¨ `ai_intent_classifier.py` é¡¶éƒ¨æ·»åŠ æ³¨é‡Š:

```python
"""
AI æ„å›¾åˆ†ç±»å™¨

æ³¨æ„: æ­¤æ¨¡å—å·²è¢« Semantic Router æ›¿ä»£ã€‚
ä»…ä½œä¸º LLM å›é€€æœºåˆ¶ä¿ç•™ã€‚
"""
```

**Step 3: Commit**

```bash
git add README.md src/chat/ai_intent_classifier.py
git commit -m "docs: update documentation for Semantic Router"
```

---

## éªŒæ”¶æ ‡å‡†

- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡
- [ ] æ„å›¾åˆ†ç±»å»¶è¿Ÿ < 100msï¼ˆæœ¬åœ° Ollama embeddingï¼‰
- [ ] å¸¸è§æ„å›¾è¯†åˆ«å‡†ç¡®ç‡ > 90%
- [ ] ä½ç½®ä¿¡åº¦æ—¶æ­£ç¡®å›é€€åˆ° LLM
- [ ] ä¸ç°æœ‰ ActionRouter å…¼å®¹

---

## å›æ»šè®¡åˆ’

å¦‚æœå‡ºç°é—®é¢˜ï¼Œå¯ä»¥ï¼š

1. è®¾ç½® `USE_SEMANTIC_ROUTER=false` å›é€€åˆ°æ—§çš„æ„å›¾åˆ†ç±»å™¨
2. æˆ–è€…ç›´æ¥å›æ»š git commits
