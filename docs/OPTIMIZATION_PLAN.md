# Personal AI Assistant ä¼˜åŒ–è®¡åˆ’

**ç‰ˆæœ¬**: v1.0
**æ—¥æœŸ**: 2026-02-25
**åŸºäº**: demo ç›®å½•ä¸‹ 4 ä¸ªé¡¹ç›®çš„å¯¹æ¯”åˆ†æ

---

## ä¸€ã€ä¼˜åŒ–ç›®æ ‡

### 1.1 æ€»ä½“ç›®æ ‡

| ç»´åº¦ | å½“å‰çŠ¶æ€ | ç›®æ ‡çŠ¶æ€ | æå‡ |
|------|---------|---------|------|
| **å¼€å‘æ•ˆç‡** | å·¥å…·å¼€å‘éœ€è¦æ ·æ¿ä»£ç  | è£…é¥°å™¨ä¸€é”®æ³¨å†Œ | 80% â†‘ |
| **ç³»ç»Ÿç¨³å®šæ€§** | å•ç‚¹æ•…éšœé£é™© | å¤šçº§ Fallback | 99.9% SLA |
| **Token æ•ˆç‡** | å›ºå®šä¸Šä¸‹æ–‡çª—å£ | åŠ¨æ€å‹ç¼© + åˆ†å±‚åŠ è½½ | 50% â†“ |
| **å¯æ‰©å±•æ€§** | å•ä¸€ CLI å…¥å£ | å¤šå¹³å°é€‚é…å™¨ | +5 å¹³å° |

### 1.2 æ ¸å¿ƒæ”¹è¿›æ–¹å‘

1. **ç®€åŒ–å·¥å…·å¼€å‘** - å¼•å…¥è£…é¥°å™¨æ³¨å†Œæœºåˆ¶
2. **å¢å¼ºè®°å¿†ç³»ç»Ÿ** - Token æ„ŸçŸ¥å‹ç¼© + Fallback é™çº§
3. **æå‡ç³»ç»Ÿç¨³å®šæ€§** - LLM/Memory å¤šçº§ Fallback
4. **æ‰©å±•è¾“å‡ºæ¸ é“** - å¤šå¹³å°é€‚é…å™¨æ¶æ„

---

## äºŒã€Phase 0: åŸºç¡€å¢å¼º (1å‘¨)

### P0-1: è£…é¥°å™¨å·¥å…·æ³¨å†Œ ğŸ”´ é«˜ä¼˜å…ˆçº§

**é—®é¢˜**: å½“å‰å·¥å…·å¼€å‘éœ€è¦åˆ›å»º Tool å­ç±»ï¼Œæ ·æ¿ä»£ç å¤š

**å€Ÿé‰´**: mini-agent-assistant çš„ `@tool()` è£…é¥°å™¨

**å®ç°æ–¹æ¡ˆ**:

```python
# æ–°æ–‡ä»¶: src/agent/tools/decorators.py

from functools import wraps
import inspect
from typing import Callable, Any
from .base import Tool, ToolParameter, ToolResult

def tool(
    name: str = None,
    description: str = None,
    timeout: float = 30.0
):
    """è£…é¥°å™¨: å°†å‡½æ•°è½¬æ¢ä¸ºå·¥å…·

    Example:
        @tool(description="æœç´¢ç½‘ç»œä¿¡æ¯")
        async def web_search(query: str, num_results: int = 5) -> str:
            '''æœç´¢ç½‘ç»œ

            Args:
                query: æœç´¢å…³é”®è¯
                num_results: è¿”å›ç»“æœæ•°é‡
            '''
            ...
    """
    def decorator(func: Callable):
        # è‡ªåŠ¨æå–å‡½æ•°ç­¾å
        sig = inspect.signature(func)
        params = _extract_parameters(sig)

        # è‡ªåŠ¨æå–æè¿°
        desc = description or _extract_description(func)

        # åˆ›å»º Tool ç±»
        class DecoratedTool(Tool):
            def __init__(self):
                self.name = name or func.__name__
                self.description = desc
                self.parameters = params
                self._func = func
                self._timeout = timeout

            async def execute(self, **kwargs) -> ToolResult:
                try:
                    result = await self._func(**kwargs)
                    return ToolResult(
                        success=True,
                        data={"result": result},
                        observation=str(result)
                    )
                except Exception as e:
                    return ToolResult(
                        success=False,
                        observation=f"æ‰§è¡Œå¤±è´¥: {e}",
                        error=str(e)
                    )

        DecoratedTool.__name__ = func.__name__
        return DecoratedTool()

    return decorator

def _extract_parameters(sig: inspect.Signature) -> list[ToolParameter]:
    """ä»å‡½æ•°ç­¾åæå–å‚æ•°å®šä¹‰"""
    params = []
    for name, param in sig.parameters.items():
        param_type = _python_type_to_json(param.annotation)
        required = param.default == inspect.Parameter.empty

        params.append(ToolParameter(
            name=name,
            type=param_type,
            description=f"å‚æ•° {name}",
            required=required,
            default=param.default if not required else None
        ))
    return params

def _extract_description(func: Callable) -> str:
    """ä» docstring æå–æè¿°"""
    doc = func.__doc__ or ""
    # å–ç¬¬ä¸€è¡Œä½œä¸ºæè¿°
    return doc.strip().split('\n')[0]
```

**æ–‡ä»¶å˜æ›´**:
- æ–°å¢: `src/agent/tools/decorators.py`
- ä¿®æ”¹: `src/agent/tools/__init__.py` (å¯¼å‡ºè£…é¥°å™¨)
- æ–°å¢: `tests/test_tool_decorators.py`

**éªŒæ”¶æ ‡å‡†**:
- [ ] `@tool()` è£…é¥°å™¨å¯æ­£å¸¸å·¥ä½œ
- [ ] è‡ªåŠ¨ä»å‡½æ•°ç­¾åç”Ÿæˆå‚æ•° schema
- [ ] æ”¯æŒ async å’Œ sync å‡½æ•°
- [ ] æµ‹è¯•è¦†ç›–ç‡ > 90%

---

### P0-2: Token æ„ŸçŸ¥ä¸Šä¸‹æ–‡å‹ç¼© ğŸ”´ é«˜ä¼˜å…ˆçº§

**é—®é¢˜**: å½“å‰ WorkingMemory ç¼ºå°‘ Token æ„ŸçŸ¥ï¼Œå¯èƒ½å¯¼è‡´ä¸Šä¸‹æ–‡æº¢å‡º

**å€Ÿé‰´**: mini-agent-assistant çš„ Memory ç±»

**å®ç°æ–¹æ¡ˆ**:

```python
# ä¿®æ”¹æ–‡ä»¶: src/memory/working_memory.py

# æ–°å¢å¸¸é‡
DEFAULT_MAX_TOKENS = 8000
TOKEN_ESTIMATE_RATIO = 0.5  # ä¸­æ–‡çº¦ 0.5 tokens/char
SUMMARY_TRIGGER_RATIO = 0.8  # 80% è§¦å‘å‹ç¼©

def estimate_tokens(text: str) -> int:
    """ä¼°ç®—æ–‡æœ¬ Token æ•°é‡"""
    if not text:
        return 0
    # ä¸­æ–‡çº¦ 0.5 tokens/charï¼Œè‹±æ–‡çº¦ 0.25 tokens/char
    char_count = len(text)
    chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
    english_chars = char_count - chinese_chars
    return int(chinese_chars * 0.5 + english_chars * 0.25)

class WorkingMemory:
    def __init__(
        self,
        max_messages: int = 50,
        max_tokens: int = DEFAULT_MAX_TOKENS,
        enable_compression: bool = True
    ):
        self.max_messages = max_messages
        self.max_tokens = max_tokens
        self.enable_compression = enable_compression
        self._summary: str = ""  # å†å²å¯¹è¯æ‘˜è¦

    def add(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯ï¼ˆå¸¦ Token æ„ŸçŸ¥ï¼‰"""
        super().add(role, content)
        self._manage_context()

    def _manage_context(self) -> None:
        """ç®¡ç†ä¸Šä¸‹æ–‡ï¼Œé˜²æ­¢è¶…å‡º Token é™åˆ¶"""
        total_tokens = self._calculate_total_tokens()

        if total_tokens <= self.max_tokens * SUMMARY_TRIGGER_RATIO:
            # åªåº”ç”¨æ¶ˆæ¯æ•°é‡é™åˆ¶
            self._trim_by_count()
            return

        # éœ€è¦å‹ç¼©ä¸Šä¸‹æ–‡
        if self.enable_compression:
            self._compress_context()
        else:
            self._trim_by_count()

    def _compress_context(self) -> None:
        """å‹ç¼©ä¸Šä¸‹æ–‡ï¼šå¯¹æ—§æ¶ˆæ¯ç”Ÿæˆæ‘˜è¦"""
        system_msgs = [m for m in self.messages if m.role == "system"]
        other_msgs = [m for m in self.messages if m.role != "system"]

        if len(other_msgs) <= 5:
            return

        # ä¿ç•™æœ€è¿‘ 5 æ¡å®Œæ•´æ¶ˆæ¯
        recent_msgs = other_msgs[-5:]
        old_msgs = other_msgs[:-5]

        # å¯¹æ—§æ¶ˆæ¯ç”Ÿæˆæ‘˜è¦ï¼ˆç®€å•å…³é”®è¯æå–ï¼‰
        topics = self._extract_topics(old_msgs)
        if topics:
            new_summary = f"ä¹‹å‰çš„å¯¹è¯æ¶‰åŠ: {', '.join(topics)}"
            self._summary = f"{self._summary}; {new_summary}" if self._summary else new_summary

        self.messages = system_msgs + recent_msgs

    def get_context_with_summary(self) -> list[dict]:
        """è·å–å¸¦æ‘˜è¦çš„ä¸Šä¸‹æ–‡"""
        messages = [m.to_dict() for m in self.messages]

        if self._summary:
            # æ’å…¥æ‘˜è¦
            summary_msg = {
                "role": "system",
                "content": f"[å†å²å¯¹è¯æ‘˜è¦] {self._summary}"
            }
            # æ’å…¥åˆ°ç¬¬ä¸€ä¸ª system æ¶ˆæ¯ä¹‹å
            for i, m in enumerate(messages):
                if m["role"] == "system":
                    messages.insert(i + 1, summary_msg)
                    break

        return messages
```

**æ–‡ä»¶å˜æ›´**:
- ä¿®æ”¹: `src/memory/working_memory.py`
- æ–°å¢: `tests/test_token_compression.py`

**éªŒæ”¶æ ‡å‡†**:
- [ ] Token ä¼°ç®—å‡†ç¡®ç‡ > 80%
- [ ] 80% é˜ˆå€¼è§¦å‘å‹ç¼©
- [ ] æ‘˜è¦ä¿ç•™å…³é”®ä¿¡æ¯
- [ ] æµ‹è¯•è¦†ç›–ç‡ > 90%

---

### P0-3: è®°å¿†ç³»ç»Ÿ Fallback æœºåˆ¶ ğŸ”´ é«˜ä¼˜å…ˆçº§

**é—®é¢˜**: å½“ä¸»å­˜å‚¨ä¸å¯ç”¨æ—¶ï¼Œç³»ç»Ÿå¯èƒ½å´©æºƒ

**å€Ÿé‰´**: viking-assistant çš„ FallbackMemoryClient

**å®ç°æ–¹æ¡ˆ**:

```python
# ä¿®æ”¹æ–‡ä»¶: src/memory/memory_system.py

class MemorySystem:
    """å¢å¼ºç‰ˆè®°å¿†ç³»ç»Ÿï¼Œæ”¯æŒ Fallback"""

    def __init__(self, config: MemoryConfig = None):
        self.config = config or MemoryConfig()
        self._primary_client = None
        self._fallback_client = None
        self._using_fallback = False

    def _ensure_client(self):
        """ç¡®ä¿æœ‰å¯ç”¨çš„å­˜å‚¨å®¢æˆ·ç«¯"""
        if self._primary_client is not None:
            return

        try:
            # å°è¯•ä¸»å­˜å‚¨
            self._primary_client = self._create_primary_client()
            logger.info("ä½¿ç”¨ä¸»å­˜å‚¨: SQLite + sqlite-vec")
        except Exception as e:
            logger.warning(f"ä¸»å­˜å‚¨åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå¯ç”¨ Fallback")
            self._fallback_client = self._create_fallback_client()
            self._using_fallback = True

    def _create_fallback_client(self):
        """åˆ›å»ºé™çº§å®¢æˆ·ç«¯ï¼ˆç®€å•æ–‡ä»¶å­˜å‚¨ï¼‰"""
        return FallbackMemoryClient(self.config.data_dir / "fallback")

    def recall(self, query: str, top_k: int = 5) -> str:
        """æœç´¢è®°å¿†ï¼ˆå¸¦ Fallbackï¼‰"""
        self._ensure_client()

        if self._using_fallback:
            return self._fallback_client.search(query, top_k)

        try:
            return self._primary_client.search(query, top_k)
        except Exception as e:
            logger.warning(f"ä¸»å­˜å‚¨æŸ¥è¯¢å¤±è´¥: {e}ï¼Œä¸´æ—¶ä½¿ç”¨ Fallback")
            return self._fallback_client.search(query, top_k)


class FallbackMemoryClient:
    """é™çº§è®°å¿†å®¢æˆ·ç«¯ - ç®€å•æ–‡ä»¶å­˜å‚¨"""

    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.data_dir.mkdir(parents=True, exist_ok=True)

    def add(self, content: str, metadata: dict = None) -> str:
        """æ·»åŠ è®°å¿†"""
        memory_id = str(uuid.uuid4())[:8]
        file_path = self.data_dir / f"{memory_id}.json"

        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump({
                "id": memory_id,
                "content": content,
                "metadata": metadata or {},
                "created_at": datetime.now().isoformat()
            }, f, ensure_ascii=False, indent=2)

        return memory_id

    def search(self, query: str, top_k: int = 5) -> str:
        """ç®€å•æœç´¢ï¼ˆå…³é”®è¯åŒ¹é…ï¼‰"""
        results = []
        query_lower = query.lower()

        for file_path in self.data_dir.glob("*.json"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                content = data.get("content", "")
                if query_lower in content.lower():
                    results.append(content)
                    if len(results) >= top_k:
                        break
            except Exception:
                continue

        return "\n---\n".join(results) if results else ""
```

**æ–‡ä»¶å˜æ›´**:
- ä¿®æ”¹: `src/memory/memory_system.py`
- æ–°å¢: `src/memory/fallback_client.py`
- æ–°å¢: `tests/test_memory_fallback.py`

**éªŒæ”¶æ ‡å‡†**:
- [ ] ä¸»å­˜å‚¨å¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢ Fallback
- [ ] Fallback æ”¯æŒåŸºæœ¬çš„ CRUD
- [ ] æ—¥å¿—è®°å½•åˆ‡æ¢äº‹ä»¶
- [ ] æµ‹è¯•è¦†ç›–ç‡ > 90%

---

## ä¸‰ã€Phase 1: æ¶æ„å¢å¼º (2å‘¨)

### P1-1: ç»Ÿä¸€ MCP ç®¡ç† ğŸŸ¡ ä¸­ä¼˜å…ˆçº§

**é—®é¢˜**: å½“å‰ MCP é›†æˆåˆ†æ•£ï¼Œç¼ºå°‘ç»Ÿä¸€ç®¡ç†

**å€Ÿé‰´**: mini-agent-assistant çš„ MCPManager

**å®ç°æ–¹æ¡ˆ**:

```python
# æ–°æ–‡ä»¶: src/tools/mcp_manager.py

class MCPToolManager:
    """ç»Ÿä¸€ MCP å·¥å…·ç®¡ç†å™¨"""

    PRESET_SERVERS = {
        "brave-search": {
            "command": "npx",
            "args": ["-y", "@modelcontextprotocol/server-brave-search"],
            "env": {"BRAVE_API_KEY": "${BRAVE_API_KEY}"}
        },
        "github": {
            "command": "npx",
            "args": ["-y", "@modelcontextprotocol/server-github"],
            "env": {"GITHUB_TOKEN": "${GITHUB_TOKEN}"}
        },
        "filesystem": {
            "command": "npx",
            "args": ["-y", "@modelcontextprotocol/server-filesystem", "${WORKSPACE}"]
        }
    }

    def __init__(self):
        self.clients: dict[str, MCPClient] = {}
        self.all_tools: list[MCPTool] = []

    def load_from_config(self, config_path: str) -> int:
        """ä»é…ç½®æ–‡ä»¶åŠ è½½ MCP æœåŠ¡å™¨"""
        with open(config_path) as f:
            config = json.load(f)

        loaded = 0
        for name, server_config in config.get("mcpServers", {}).items():
            try:
                client = MCPClient(server_config)
                self.clients[name] = client
                self.all_tools.extend(client.list_tools())
                loaded += 1
            except Exception as e:
                logger.warning(f"åŠ è½½ MCP æœåŠ¡å™¨ {name} å¤±è´¥: {e}")

        return loaded

    def load_presets(self, presets: list[str]) -> int:
        """åŠ è½½é¢„è®¾æœåŠ¡å™¨"""
        loaded = 0
        for name in presets:
            if name in self.PRESET_SERVERS:
                config = self._resolve_env_vars(self.PRESET_SERVERS[name])
                try:
                    client = MCPClient(config)
                    self.clients[name] = client
                    self.all_tools.extend(client.list_tools())
                    loaded += 1
                except Exception as e:
                    logger.warning(f"åŠ è½½é¢„è®¾ {name} å¤±è´¥: {e}")
        return loaded

    def to_openai_schemas(self) -> list[dict]:
        """è½¬æ¢ä¸º OpenAI Function Schema"""
        return [tool.to_schema() for tool in self.all_tools]

    def execute(self, name: str, arguments: dict) -> str:
        """æ‰§è¡Œ MCP å·¥å…·"""
        for client in self.clients.values():
            if client.has_tool(name):
                return client.call_tool(name, arguments)
        raise ValueError(f"MCP å·¥å…·æœªæ‰¾åˆ°: {name}")
```

**æ–‡ä»¶å˜æ›´**:
- æ–°å¢: `src/tools/mcp_manager.py`
- ä¿®æ”¹: `src/agent/supervisor.py` (é›†æˆ MCPManager)
- æ–°å¢: `config/mcp_presets.json`

**éªŒæ”¶æ ‡å‡†**:
- [ ] æ”¯æŒ JSON é…ç½®åŠ è½½
- [ ] æ”¯æŒé¢„è®¾æœåŠ¡å™¨å¿«é€Ÿå¯ç”¨
- [ ] ç»Ÿä¸€çš„ OpenAI Schema è¾“å‡º
- [ ] æµ‹è¯•è¦†ç›–ç‡ > 80%

---

### P1-2: å¤šå¹³å°é€‚é…å™¨æ¶æ„ ğŸŸ¡ ä¸­ä¼˜å…ˆçº§

**é—®é¢˜**: å½“å‰åªæœ‰ CLI å…¥å£ï¼Œç¼ºå°‘å¤šå¹³å°æ”¯æŒ

**å€Ÿé‰´**: dev-assistant-demo çš„é€‚é…å™¨æ¶æ„

**å®ç°æ–¹æ¡ˆ**:

```
src/channels/
â”œâ”€â”€ __init__.py          # å·¥å‚å‡½æ•°
â”œâ”€â”€ base.py              # åŸºç±»å®šä¹‰
â”œâ”€â”€ console.py           # æ§åˆ¶å°é€‚é…å™¨
â”œâ”€â”€ telegram.py          # Telegram é€‚é…å™¨
â”œâ”€â”€ discord.py           # Discord é€‚é…å™¨
â””â”€â”€ feishu.py            # é£ä¹¦é€‚é…å™¨
```

```python
# src/channels/base.py

from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Callable, AsyncGenerator

@dataclass
class ChatMessage:
    """ç»Ÿä¸€æ¶ˆæ¯æ ¼å¼"""
    chat_id: str
    user_id: str
    content: str
    metadata: dict = None

@dataclass
class ChatResponse:
    """ç»Ÿä¸€å“åº”æ ¼å¼"""
    content: str
    success: bool = True
    metadata: dict = None

class ChannelAdapter(ABC):
    """æ¸ é“é€‚é…å™¨åŸºç±»"""

    def __init__(self, config: dict):
        self.config = config
        self._message_handlers: list[Callable] = []

    @abstractmethod
    async def start(self):
        """å¯åŠ¨é€‚é…å™¨"""
        pass

    @abstractmethod
    async def stop(self):
        """åœæ­¢é€‚é…å™¨"""
        pass

    @abstractmethod
    async def send_message(self, chat_id: str, content: str):
        """å‘é€æ¶ˆæ¯"""
        pass

    def on_message(self, handler: Callable[[ChatMessage], AsyncGenerator[str, None]]):
        """æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨"""
        self._message_handlers.append(handler)

    async def _dispatch_message(self, message: ChatMessage):
        """åˆ†å‘æ¶ˆæ¯åˆ°å¤„ç†å™¨"""
        for handler in self._message_handlers:
            async for chunk in handler(message):
                await self.send_message(message.chat_id, chunk)


# src/channels/__init__.py

def get_channel(name: str, config: dict) -> ChannelAdapter:
    """å·¥å‚å‡½æ•°: è·å–æ¸ é“é€‚é…å™¨"""
    channels = {
        "console": ConsoleAdapter,
        "telegram": TelegramAdapter,
        "discord": DiscordAdapter,
        "feishu": FeishuAdapter,
    }

    adapter_class = channels.get(name)
    if adapter_class is None:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¸ é“: {name}")

    return adapter_class(config)
```

**æ–‡ä»¶å˜æ›´**:
- æ–°å¢: `src/channels/` ç›®å½•
- æ–°å¢: `src/channels/base.py`
- æ–°å¢: `src/channels/console.py`
- æ–°å¢: `src/channels/telegram.py` (éª¨æ¶)
- ä¿®æ”¹: `src/main.py` (æ”¯æŒæ¸ é“é€‰æ‹©)

**éªŒæ”¶æ ‡å‡†**:
- [ ] ConsoleAdapter å®Œæ•´å®ç°
- [ ] TelegramAdapter åŸºæœ¬åŠŸèƒ½
- [ ] ç»Ÿä¸€æ¶ˆæ¯æ ¼å¼
- [ ] æµ‹è¯•è¦†ç›–ç‡ > 70%

---

### P1-3: LLM Provider Fallback ğŸŸ¡ ä¸­ä¼˜å…ˆçº§

**é—®é¢˜**: å½“å‰ LLM Adapter ç¼ºå°‘ Fallback æœºåˆ¶

**å€Ÿé‰´**: dev-assistant-demo çš„ AIEngine

**å®ç°æ–¹æ¡ˆ**:

```python
# ä¿®æ”¹æ–‡ä»¶: src/agent/llm_adapter.py

@dataclass
class LLMConfig:
    """LLM é…ç½®"""
    provider: str = "openai"
    api_key: str = None
    base_url: str = None
    model: str = "gpt-4o-mini"

    # Fallback é…ç½®
    fallback_enabled: bool = False
    fallback_provider: str = "ollama"
    fallback_base_url: str = "http://localhost:11434"
    fallback_model: str = "qwen2.5:14b"


class LLMAdapter:
    """å¢å¼ºç‰ˆ LLM é€‚é…å™¨ï¼Œæ”¯æŒ Fallback"""

    def __init__(self, config: LLMConfig):
        self.config = config
        self._primary = self._create_provider(
            config.provider,
            config.api_key,
            config.base_url,
            config.model
        )

        self._fallback = None
        if config.fallback_enabled:
            self._fallback = self._create_provider(
                config.fallback_provider,
                None,  # æœ¬åœ°æ¨¡å‹æ— éœ€ API Key
                config.fallback_base_url,
                config.fallback_model
            )

    async def generate(
        self,
        messages: list[dict],
        stream: bool = False,
        **kwargs
    ) -> str | AsyncGenerator:
        """ç”Ÿæˆå“åº”ï¼ˆå¸¦ Fallbackï¼‰"""
        try:
            return await self._call_primary(messages, stream, **kwargs)
        except Exception as e:
            logger.warning(f"ä¸» LLM è°ƒç”¨å¤±è´¥: {e}")
            if self._fallback:
                logger.info("åˆ‡æ¢åˆ° Fallback LLM")
                return await self._call_fallback(messages, stream, **kwargs)
            raise

    async def _call_primary(self, messages, stream, **kwargs):
        """è°ƒç”¨ä¸» LLM"""
        if stream:
            return self._primary.stream_chat(messages, **kwargs)
        return await self._primary.chat(messages, **kwargs)

    async def _call_fallback(self, messages, stream, **kwargs):
        """è°ƒç”¨ Fallback LLM"""
        if stream:
            return self._fallback.stream_chat(messages, **kwargs)
        return await self._fallback.chat(messages, **kwargs)
```

**æ–‡ä»¶å˜æ›´**:
- ä¿®æ”¹: `src/agent/llm_adapter.py`
- ä¿®æ”¹: `src/config/settings.py` (æ·»åŠ  Fallback é…ç½®)
- æ–°å¢: `tests/test_llm_fallback.py`

**éªŒæ”¶æ ‡å‡†**:
- [ ] ä¸» LLM å¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢ Fallback
- [ ] æ”¯æŒ OpenAI â†’ Ollama åˆ‡æ¢
- [ ] æ—¥å¿—è®°å½•åˆ‡æ¢äº‹ä»¶
- [ ] æµ‹è¯•è¦†ç›–ç‡ > 80%

---

## å››ã€Phase 2: åŠŸèƒ½å¢å¼º (1-2å‘¨)

### P2-1: Session Notes åŠŸèƒ½ ğŸŸ¢ ä½ä¼˜å…ˆçº§

**å€Ÿé‰´**: mini-agent-assistant çš„ SessionNotes

**å®ç°æ–¹æ¡ˆ**:

```python
# æ–°æ–‡ä»¶: src/notes/manager.py

@dataclass
class Note:
    id: str
    title: str
    content: str
    created_at: str
    updated_at: str

class SessionNotes:
    """è·¨ä¼šè¯ç¬”è®°ç®¡ç†å™¨"""

    def __init__(self, storage_path: str = None):
        self.storage_path = storage_path or str(
            Path.home() / ".personal-assistant" / "notes.json"
        )
        self.notes: dict[str, Note] = {}
        self._load()

    def create(self, title: str, content: str) -> Note:
        """åˆ›å»ºç¬”è®°"""
        note_id = str(uuid.uuid4())[:8]
        note = Note(
            id=note_id,
            title=title,
            content=content,
            created_at=datetime.now().isoformat(),
            updated_at=datetime.now().isoformat()
        )
        self.notes[note_id] = note
        self._save()
        return note

    def search(self, keyword: str) -> list[Note]:
        """æœç´¢ç¬”è®°"""
        keyword = keyword.lower()
        return [
            note for note in self.notes.values()
            if keyword in note.title.lower() or keyword in note.content.lower()
        ]
```

**å·¥å…·é›†æˆ**:

```python
@tool(description="åˆ›å»ºè·¨ä¼šè¯ç¬”è®°")
def create_note(title: str, content: str) -> str:
    """åˆ›å»ºä¸€æ¡ç¬”è®°ï¼Œåœ¨åç»­ä¼šè¯ä¸­å¯ç”¨"""
    ...

@tool(description="æœç´¢ç¬”è®°")
def search_notes(keyword: str) -> str:
    """æœç´¢ä¹‹å‰åˆ›å»ºçš„ç¬”è®°"""
    ...
```

---

### P2-2: è®°å¿†ç”Ÿå‘½å‘¨æœŸç®¡ç† ğŸŸ¢ ä½ä¼˜å…ˆçº§

**å€Ÿé‰´**: dev-assistant-demo çš„ P0/P1/P2 ä¼˜å…ˆçº§

**å®ç°æ–¹æ¡ˆ**:

```python
@dataclass
class MemoryEntry:
    content: str
    priority: str = "P1"  # P0=æ°¸ä¹…, P1=90å¤©, P2=30å¤©
    created_at: datetime = field(default_factory=datetime.now)
    last_accessed: datetime = field(default_factory=datetime.now)

    def decay_weight(self) -> float:
        """åŸºäºè‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿è®¡ç®—æƒé‡è¡°å‡"""
        days = (datetime.now() - self.last_accessed).days

        if self.priority == "P0":
            return 1.0  # æ°¸ä¸è¡°å‡
        elif self.priority == "P1":
            return max(0.1, 2 ** (-days / 30))  # 30å¤©åŠè¡°
        else:  # P2
            return max(0.05, 2 ** (-days / 7))  # 7å¤©åŠè¡°

    def should_archive(self) -> bool:
        """æ˜¯å¦åº”è¯¥å½’æ¡£"""
        return self.decay_weight() < 0.1
```

---

## äº”ã€å®æ–½è®¡åˆ’

### 5.1 æ—¶é—´çº¿

```
Week 1: P0-1 è£…é¥°å™¨å·¥å…·æ³¨å†Œ + P0-2 Token å‹ç¼©
Week 2: P0-3 è®°å¿† Fallback + P1-1 MCP ç®¡ç†
Week 3: P1-2 å¤šå¹³å°é€‚é…å™¨ + P1-3 LLM Fallback
Week 4: P2-1 Session Notes + æµ‹è¯•å®Œå–„
```

### 5.2 é‡Œç¨‹ç¢‘

| é‡Œç¨‹ç¢‘ | æ—¶é—´ | äº¤ä»˜ç‰© |
|--------|------|--------|
| **M1** | Week 1 ç»“æŸ | è£…é¥°å™¨å·¥å…· + Token å‹ç¼© |
| **M2** | Week 2 ç»“æŸ | Fallback æœºåˆ¶ + MCP ç®¡ç† |
| **M3** | Week 3 ç»“æŸ | å¤šå¹³å°é€‚é…å™¨ + LLM Fallback |
| **M4** | Week 4 ç»“æŸ | Session Notes + å…¨éƒ¨æµ‹è¯• |

### 5.3 èµ„æºéœ€æ±‚

| èµ„æº | ç”¨é€” |
|------|------|
| å¼€å‘æ—¶é—´ | çº¦ 4 å‘¨ |
| API Key | Brave Search, GitHub Token (å¯é€‰) |
| æœåŠ¡å™¨ | Telegram/Discord Bot æ‰˜ç®¡ (å¯é€‰) |

---

## å…­ã€é£é™©è¯„ä¼°

| é£é™© | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|---------|
| LLM API å˜æ›´ | é«˜ | æŠ½è±¡å±‚éš”ç¦»ï¼Œå¿«é€Ÿé€‚é… |
| ç¬¬ä¸‰æ–¹åº“ä¾èµ– | ä¸­ | ç‰ˆæœ¬é”å®šï¼Œå¤‡ç”¨æ–¹æ¡ˆ |
| Token ä¼°ç®—ä¸å‡† | ä¸­ | å¤šç§ä¼°ç®—ç®—æ³•ï¼ŒåŠ¨æ€è°ƒæ•´ |
| å¤šå¹³å°é€‚é…å¤æ‚ | ä¸­ | ä¼˜å…ˆå®ç°æ ¸å¿ƒå¹³å° |

---

## ä¸ƒã€éªŒæ”¶æ ‡å‡†

### 7.1 åŠŸèƒ½éªŒæ”¶

- [ ] æ‰€æœ‰ P0 åŠŸèƒ½å®Œæˆå¹¶æµ‹è¯•é€šè¿‡
- [ ] æ‰€æœ‰ P1 åŠŸèƒ½å®Œæˆå¹¶æµ‹è¯•é€šè¿‡
- [ ] æµ‹è¯•è¦†ç›–ç‡ > 80%
- [ ] æ–‡æ¡£æ›´æ–°å®Œæˆ

### 7.2 æ€§èƒ½éªŒæ”¶

- [ ] å·¥å…·æ³¨å†Œæ—¶é—´ < 100ms
- [ ] Token å‹ç¼©å‡†ç¡®ç‡ > 80%
- [ ] Fallback åˆ‡æ¢æ—¶é—´ < 1s
- [ ] å†…å­˜ä½¿ç”¨ < 200MB

### 7.3 è´¨é‡éªŒæ”¶

- [ ] Ruff æ£€æŸ¥å…¨éƒ¨é€šè¿‡
- [ ] Mypy ç±»å‹æ£€æŸ¥é€šè¿‡
- [ ] æ— é«˜å±å®‰å…¨é—®é¢˜
- [ ] ä»£ç è¯„å®¡é€šè¿‡

---

*è®¡åˆ’åˆ›å»ºæ—¶é—´: 2026-02-25*
*è®¡åˆ’è´Ÿè´£äºº: AI Assistant*
